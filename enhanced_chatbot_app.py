import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import re
import time
from gpt_chatbot import GPTChatbot
import config
import os
import json
from difflib import SequenceMatcher
from collections import Counter

# ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class SmartSearchSystem:
    def __init__(self):
        # í‚¤ì›Œë“œ ì‚¬ì „ ë¡œë“œ
        try:
            with open('business_keywords.json', 'r', encoding='utf-8') as f:
                self.keyword_dict = json.load(f)
            
            with open('similar_industries.json', 'r', encoding='utf-8') as f:
                self.similar_industries = json.load(f)
        except FileNotFoundError:
            # Streamlit ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ ê²½ê³  í‘œì‹œ
            try:
                st.warning("í‚¤ì›Œë“œ ì‚¬ì „ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            except:
                # Streamlit ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê²½ê³  ì—†ì´ ì§„í–‰
                pass
            self.keyword_dict = {}
            self.similar_industries = {}
    
    def find_exact_match(self, query):
        """1ì°¨ ê²€ìƒ‰: DBì— ìˆëŠ” ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ìš°ì„ )"""
        query_lower = query.lower()
        exact_matches = []
        
        # íŠ¹ì • í‚¤ì›Œë“œ ê·¸ë£¹ì´ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
        priority_keywords = ['ai', 'í´ë¼ìš°ë“œ', 'ë¸”ë¡ì²´ì¸', 'iot', 'ë°”ì´ì˜¤', 'ì‹ ì¬ìƒì—ë„ˆì§€', 'ì „ê¸°ì°¨', 'ë°˜ë„ì²´']
        question_has_priority_keyword = any(keyword in query_lower for keyword in priority_keywords)
        
        # ëª¨ë“  í‚¤ì›Œë“œì—ì„œ ì •í™•í•œ ë§¤ì¹­ ì°¾ê¸°
        for category, keywords in self.keyword_dict.items():
            if category != 'all_keywords':
                for keyword in keywords:
                    if keyword.lower() in query_lower:
                        # í‚¤ì›Œë“œ ê¸¸ì´ì™€ í¬í•¨ ì—¬ë¶€ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ê³„ì‚°
                        priority_score = 0
                        
                        # 1ìˆœìœ„: ì§ˆë¬¸ì— ì •í™•íˆ í¬í•¨ëœ í‚¤ì›Œë“œ
                        if keyword.lower() in query_lower:
                            priority_score += 1000
                        
                        # 2ìˆœìœ„: í‚¤ì›Œë“œ ê¸¸ì´ (ê¸´ ê²ƒ ìš°ì„ ) - ë³µí•© í‚¤ì›Œë“œ ìš°ì„ 
                        priority_score += len(keyword) * 10  # ê¸¸ì´ì— ë” í° ê°€ì¤‘ì¹˜
                        
                        # 3ìˆœìœ„: ë³µí•© í‚¤ì›Œë“œ ìš°ì„  (ê³µë°±ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ ì—†ëŠ” ê¸´ í‚¤ì›Œë“œ)
                        if len(keyword) >= 4 and ' ' not in keyword and keyword.isalnum():
                            priority_score += 500
                        
                        # 4ìˆœìœ„: íŠ¹ì • í‚¤ì›Œë“œ ê·¸ë£¹ ìš°ì„  (AI, í´ë¼ìš°ë“œ, ë¸”ë¡ì²´ì¸ ë“±) - ë§¤ìš° ë†’ì€ ìš°ì„ ìˆœìœ„
                        if keyword.lower() in priority_keywords:
                            priority_score += 800  # ë§¤ìš° ë†’ì€ ìš°ì„ ìˆœìœ„
                            
                            # ì§ˆë¬¸ì— ìš°ì„  í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê³ , í˜„ì¬ í‚¤ì›Œë“œê°€ ê·¸ ì¤‘ í•˜ë‚˜ë¼ë©´ ìµœìš°ì„  ì²˜ë¦¬
                            if question_has_priority_keyword:
                                priority_score += 2000  # ì¶”ê°€ ë³´ë„ˆìŠ¤
                        
                        # 5ìˆœìœ„: ì¼ë°˜ì ì¸ ë‹¨ì–´ ê°•ë ¥í•œ í˜ë„í‹° (ì†”ë£¨ì…˜, í”Œë«í¼, ì‹œìŠ¤í…œ ë“±)
                        general_words = ['ì†”ë£¨ì…˜', 'í”Œë«í¼', 'ì‹œìŠ¤í…œ', 'ì„œë¹„ìŠ¤', 'ê¸°ìˆ ', 'ê°œë°œ', 'ì œê³µ', 'ì—…ê³„', 'ì‚¬ì—…']
                        if keyword.lower() in general_words:
                            priority_score -= 600  # ê°•ë ¥í•œ í˜ë„í‹°
                            
                            # ì§ˆë¬¸ì— ìš°ì„  í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì„ ë•ŒëŠ” ì¼ë°˜ ë‹¨ì–´ì— ë” ê°•í•œ í˜ë„í‹°
                            if question_has_priority_keyword:
                                priority_score -= 1000  # ì¶”ê°€ í˜ë„í‹°
                        
                        # 6ìˆœìœ„: ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜
                        category_weights = {
                            'it_software': 100,
                            'game': 100,
                            'finance': 100,
                            'manufacturing': 100,
                            'security': 100
                        }
                        priority_score += category_weights.get(category, 0)
                        
                        exact_matches.append({
                            'keyword': keyword,
                            'category': category,
                            'match_type': 'exact',
                            'confidence': 1.0,
                            'priority_score': priority_score
                        })
        
        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
        exact_matches.sort(key=lambda x: x['priority_score'], reverse=True)
        
        return exact_matches
    
    def find_similar_industries(self, query):
        """2ì°¨ ê²€ìƒ‰: ìœ ì‚¬ì„±ì´ ë†’ì€ ì—…ì¢… ì°¾ê¸°"""
        query_lower = query.lower()
        similar_matches = []
        
        # ìœ ì‚¬ ì—…ì¢… ë§¤í•‘ì—ì„œ ì°¾ê¸°
        for industry, related_keywords in self.similar_industries.items():
            if industry.lower() in query_lower:
                similar_matches.append({
                    'keyword': industry,
                    'related_keywords': related_keywords,
                    'match_type': 'similar_industry',
                    'confidence': 0.9
                })
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        for keyword in self.keyword_dict.get('all_keywords', []):
            similarity = SequenceMatcher(None, query_lower, keyword.lower()).ratio()
            if similarity > 0.6:
                similar_matches.append({
                    'keyword': keyword,
                    'related_keywords': [keyword],
                    'match_type': 'similarity_based',
                    'confidence': similarity
                })
        
        return similar_matches
    
    def smart_search(self, query):
        """ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰: 1ì°¨ ì •í™• ë§¤ì¹­ + 2ì°¨ ìœ ì‚¬ ì—…ì¢… ê²€ìƒ‰"""
        # 1ì°¨ ê²€ìƒ‰: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        exact_matches = self.find_exact_match(query)
        
        # 2ì°¨ ê²€ìƒ‰: ìœ ì‚¬ ì—…ì¢… ê²€ìƒ‰
        similar_matches = self.find_similar_industries(query)
        
        # ê²°ê³¼ í†µí•© ë° ì •ë ¬
        all_matches = exact_matches + similar_matches
        all_matches.sort(key=lambda x: x['confidence'], reverse=True)
        
        return all_matches

# ì „ì—­ ë³€ìˆ˜ë¡œ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
@st.cache_resource
def get_smart_search_system():
    return SmartSearchSystem()

def process_valuation_analysis(question):
    """ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ ì§ˆë¬¸ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        question_lower = question.lower()
        
        # SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ
        db_path = 'ì™¸í‰ë³´ê³ ì„œ.db'
        if not os.path.exists(db_path):
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
            st.info("Excel íŒŒì¼ì„ ë¨¼ì € DBë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”: python excel_to_db.py")
            return False
        
        import sqlite3
        conn = sqlite3.connect(db_path)
        df = pd.read_sql_query("SELECT * FROM ì™¸í‰ë³´ê³ ì„œ", conn)
        conn.close()
        
        if df.empty:
            st.warning("ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # DBì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ëŠ” ì´ë¯¸ ì»¬ëŸ¼ëª…ì´ ì •ë¦¬ë˜ì–´ ìˆìŒ
        # í•˜ì§€ë§Œ ì¼ë¶€ ì»¬ëŸ¼ëª… ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
        column_mapping = {
            'í‰ê°€ëŒ€ìƒ ê¸°ì—…ëª…': 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…',  # ê³µë°±ì´ ìˆëŠ” ì»¬ëŸ¼ëª… ìˆ˜ì •
            'ì¶”ì •ê¸°ê°„_í˜„ì¬ê°€ì¹˜_ì˜ì—…ê°€ì¹˜': 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜',
            'NOA_Enterprise_Value': 'NOA / Enterprise Value'
        }
        
        for old_col, new_col in column_mapping.items():
            if old_col in df.columns:
                df.rename(columns={old_col: new_col}, inplace=True)
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
        numeric_columns = ['WACC', 'Ke', 'Kd', 'D/E', 'EV/Sales', 'PSR', 'PER', 'EV/EBITDA', 'PBR', 'NOA / Enterprise Value', 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜']
        for col in numeric_columns:
            if col in df.columns:
                # Handle both decimal format (0.178) and percentage format (17.78%)
                col_data = df[col].astype(str).str.replace(',', '').str.replace('\t', '')
                has_percent = col_data.str.contains('%', na=False)
                
                # Convert to numeric, removing % symbol
                numeric_data = pd.to_numeric(col_data.str.replace('%', ''), errors='coerce')
                
                # For values that had % symbol, divide by 100 to convert to decimal
                numeric_data[has_percent] = numeric_data[has_percent] / 100
                
                df[col] = numeric_data
        
        # g ì»¬ëŸ¼ ì²˜ë¦¬ (ì˜êµ¬ì„±ì¥ë¥ )
        g_columns = ['g', 'ì˜êµ¬ì„±ì¥ë¥ ', 'ì˜êµ¬ì„±ì¥', 'ì˜êµ¬ì„±ì¥ìœ¨']
        for g_col in g_columns:
            if g_col in df.columns:
                df['g'] = pd.to_numeric(df[g_col].astype(str).str.replace(',', '').str.replace('%', ''), errors='coerce')
                break
        
        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        if 'ë°œí–‰ì¼ì' in df.columns:
            df['ë°œí–‰ì¼ì'] = pd.to_datetime(df['ë°œí–‰ì¼ì'], errors='coerce')
        
        # 1. ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’
        if "ì‚°ì—…ë³„" in question and "wacc" in question_lower and "ì¤‘ì•™ê°’" in question:
            if 'WACC' in df.columns and 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df.columns:
                grp = df.groupby('ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜')['WACC'].median().dropna().sort_values(ascending=False)
                if not grp.empty:
                    st.subheader('ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’')
                    # Convert to percentage for display
                    grp_display = grp * 100
                    st.dataframe(grp_display.reset_index().rename(columns={'WACC': 'WACC ì¤‘ì•™ê°’ (%)'}), hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(x=grp_display.values, y=grp_display.index, orientation='h', 
                                title='ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’', labels={'x': 'WACC ì¤‘ì•™ê°’ (%)', 'y': 'ì‚°ì—…ë¶„ë¥˜'})
                    st.plotly_chart(fig, use_container_width=True)
                    return True
        
        # 2. í‰ê°€ë²•ì¸ë³„ WACC ë¹„êµ
        elif "í‰ê°€ë²•ì¸" in question and "wacc" in question_lower and ("ë¹„êµ" in question or "ì¤‘ì•™ê°’" in question):
            if 'WACC' in df.columns and 'í‰ê°€ë²•ì¸' in df.columns:
                grp = df.groupby('í‰ê°€ë²•ì¸')['WACC'].median().dropna().sort_values(ascending=False)
                if not grp.empty:
                    st.subheader('í‰ê°€ë²•ì¸ë³„ WACC ì¤‘ì•™ê°’ ë¹„êµ')
                    # Convert to percentage for display
                    grp_display = grp * 100
                    st.dataframe(grp_display.reset_index().rename(columns={'WACC': 'WACC ì¤‘ì•™ê°’ (%)'}), hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(x=grp_display.values, y=grp_display.index, orientation='h', 
                                title='í‰ê°€ë²•ì¸ë³„ WACC ì¤‘ì•™ê°’', labels={'x': 'WACC ì¤‘ì•™ê°’ (%)', 'y': 'í‰ê°€ë²•ì¸'})
                    st.plotly_chart(fig, use_container_width=True)
                    return True
        
        # 3. g â‰¥ WACC ìœ„ë°˜ ì‚¬ë¡€
        elif ("ìœ„ë°˜" in question or "g" in question_lower) and "wacc" in question_lower:
            if 'g' in df.columns and 'WACC' in df.columns:
                vio = df[(pd.to_numeric(df['g'], errors='coerce') >= pd.to_numeric(df['WACC'], errors='coerce'))]
                st.subheader('QC: g â‰¥ WACC ìœ„ë°˜ ì‚¬ë¡€')
                st.write(f'ì´ {len(vio)}ê±´ì˜ ìœ„ë°˜ ì‚¬ë¡€ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.')
                
                if not vio.empty:
                    display_cols = ['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ë°œí–‰ì¼ì', 'g', 'WACC', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜']
                    available_cols = [col for col in display_cols if col in vio.columns]
                    
                    if 'ë°œí–‰ì¼ì' in vio.columns:
                        vio_sorted = vio.sort_values('ë°œí–‰ì¼ì', ascending=False)
                    else:
                        vio_sorted = vio
                    
                    st.dataframe(vio_sorted[available_cols], hide_index=True, use_container_width=True)
                    return True
        
        # 4. D/E ë¯¸ê¸°ì¬ ì˜í–¥
        elif "ë¯¸ê¸°ì¬" in question and ("d/e" in question_lower or "ë¶€ì±„ë¹„ìœ¨" in question):
            if 'D/E' in df.columns and 'WACC' in df.columns:
                de = pd.to_numeric(df['D/E'], errors='coerce')
                w = pd.to_numeric(df['WACC'], errors='coerce')
                missing = w[de.isna()].dropna()
                present = w[de.notna()].dropna()
                
                st.subheader('QC: D/E ë¯¸ê¸°ì¬ê°€ WACCì— ë¯¸ì¹˜ëŠ” ì˜í–¥')
                
                pct_missing = (len(missing)/(len(missing)+len(present)))*100 if (len(missing)+len(present))>0 else 0
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric('D/E ë¯¸ê¸°ì¬ ë¹„ì¤‘', f'{pct_missing:.1f}%')
                with col2:
                    if len(missing) > 0:
                        st.metric('ë¯¸ê¸°ì¬ ê·¸ë£¹ í‰ê·  WACC', f'{missing.mean() * 100:.2f}%')
                    else:
                        st.metric('ë¯¸ê¸°ì¬ ê·¸ë£¹ í‰ê·  WACC', 'N/A')
                with col3:
                    if len(present) > 0:
                        st.metric('ê¸°ì¬ ê·¸ë£¹ í‰ê·  WACC', f'{present.mean() * 100:.2f}%')
                    else:
                        st.metric('ê¸°ì¬ ê·¸ë£¹ í‰ê·  WACC', 'N/A')
                
                if len(missing)>0 and len(present)>0:
                    st.metric('í‰ê·  WACC ì°¨ì´(ë¯¸ê¸°ì¬-ê¸°ì¬)', f'{(missing.mean()-present.mean()) * 100:.2f}%p')
                
                return True
        
        # 5. WACC Top 10 ë˜ëŠ” ìƒìœ„ Nê°œ
        elif ("top" in question_lower or "ìƒìœ„" in question) and "wacc" in question_lower:
            if 'WACC' in df.columns:
                # ìƒìœ„ Nê°œ ì¶”ì¶œ
                import re
                n = 10  # ê¸°ë³¸ê°’
                match = re.search(r'(?:top|ìƒìœ„)\s*(\d+)', question_lower)
                if match:
                    try:
                        n = int(match.group(1))
                    except:
                        n = 10
                
                display_cols = ['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'WACC']
                available_cols = [col for col in display_cols if col in df.columns]
                
                topn = df[available_cols].dropna(subset=['WACC']).sort_values('WACC', ascending=False).head(n)
                
                st.subheader(f'ë­í‚¹: WACC Top {n}')
                # Convert WACC to percentage for display
                topn_display = topn.copy()
                topn_display['WACC'] = topn_display['WACC'] * 100
                topn_display = topn_display.rename(columns={'WACC': 'WACC (%)'})
                st.dataframe(topn_display, hide_index=True, use_container_width=True)
                
                # ì°¨íŠ¸ ìƒì„±
                if not topn.empty:
                    fig = px.bar(x=topn['WACC'] * 100, y=topn['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'], orientation='h',
                                title=f'WACC Top {n}', labels={'x': 'WACC (%)', 'y': 'ê¸°ì—…ëª…'})
                    st.plotly_chart(fig, use_container_width=True)
                
                return True
        
        # 6. ìµœê·¼ 12ê°œì›” í‰ê°€ë²•ì¸ TOP5
        elif "ìµœê·¼" in question and ("í‰ê°€ë²•ì¸" in question or "íšŒê³„ë²•ì¸" in question):
            if 'í‰ê°€ë²•ì¸' in df.columns and 'ë°œí–‰ì¼ì' in df.columns:
                cutoff = df['ë°œí–‰ì¼ì'].max()
                if pd.notna(cutoff):
                    recent = df[df['ë°œí–‰ì¼ì'] >= (cutoff - pd.Timedelta(days=365))]
                    counts = recent.groupby('í‰ê°€ë²•ì¸')['í‰ê°€ë²•ì¸'].count().sort_values(ascending=False).head(5)
                    
                    st.subheader('ë­í‚¹: ìµœê·¼ 12ê°œì›” í‰ê°€ë²•ì¸ TOP5')
                    st.dataframe(counts.reset_index(name='ê±´ìˆ˜'), hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(x=counts.values, y=counts.index, orientation='h',
                                title='ìµœê·¼ 12ê°œì›” í‰ê°€ë²•ì¸ í™œë™ëŸ‰ TOP5', labels={'x': 'ê±´ìˆ˜', 'y': 'í‰ê°€ë²•ì¸'})
                    st.plotly_chart(fig, use_container_width=True)
                    
                    return True
        
        # 7. ì‚°ì—…ë³„ ë©€í‹°í”Œ ì¤‘ì•™ê°’
        elif "ì‚°ì—…ë³„" in question and "ì¤‘ì•™ê°’" in question and any(mult in question for mult in ['EV/EBITDA', 'EV/Sales', 'PSR', 'PER', 'PBR']):
            # ë©€í‹°í”Œ ì¢…ë¥˜ í™•ì¸
            metric = None
            for mult in ['EV/EBITDA', 'EV/Sales', 'PSR', 'PER', 'PBR']:
                if mult in question:
                    metric = mult
                    break
            
            if not metric:
                metric = 'EV/EBITDA'  # ê¸°ë³¸ê°’
            
            if metric in df.columns and 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df.columns:
                grp = df.groupby('ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜')[metric].median().dropna().sort_values(ascending=False)
                if not grp.empty:
                    st.subheader(f'ì‚°ì—…ë³„ {metric} ì¤‘ì•™ê°’')
                    st.dataframe(grp.reset_index().rename(columns={metric: f'{metric} ì¤‘ì•™ê°’'}), hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(x=grp.values, y=grp.index, orientation='h',
                                title=f'ì‚°ì—…ë³„ {metric} ì¤‘ì•™ê°’', labels={'x': f'{metric} ì¤‘ì•™ê°’', 'y': 'ì‚°ì—…ë¶„ë¥˜'})
                    st.plotly_chart(fig, use_container_width=True)
                    return True
        
        # 8. ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ê´€ë ¨ (ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜ ì»¬ëŸ¼ í™œìš©)
        elif "ì˜êµ¬í˜„ê¸ˆíë¦„" in question and "ë¹„ìœ¨" in question:
            st.subheader('ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ë¶„ì„')
            
            # ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜' in df.columns:
                # ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ê³„ì‚°: 1 - (ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜)
                cash_flow_data = df[['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜']].dropna(subset=['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜'])
                
                if not cash_flow_data.empty:
                    # ì´ìƒê°’ í•„í„°ë§ (0ê³¼ 1 ì‚¬ì´ì˜ ê°’ë§Œ ìœ íš¨)
                    valid_data = cash_flow_data[
                        (cash_flow_data['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜'] >= 0) & 
                        (cash_flow_data['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜'] <= 1)
                    ].copy()
                    
                    if valid_data.empty:
                        st.warning("ìœ íš¨í•œ ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return True
                    
                    # ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ê³„ì‚°
                    valid_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'] = 1 - valid_data['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜']
                    
                    # 50% ì´ìƒì¸ ê¸°ì—…ë“¤ í•„í„°ë§
                    high_ratio_companies = valid_data[valid_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'] >= 0.5]
                    
                    st.markdown("### ğŸ“Š ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ê¸°ì—…ë“¤")
                    
                    if not high_ratio_companies.empty:
                        # ìƒìœ„ 10ê°œ ê¸°ì—… í‘œì‹œ
                        top_companies = high_ratio_companies.sort_values('ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨', ascending=False).head(10)
                        
                        # ë°ì´í„° í‘œì‹œ
                        display_data = top_companies[['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨', 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜']].copy()
                        display_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'] = display_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'].apply(lambda x: f"{x:.1%}")
                        display_data['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜'] = display_data['ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜'].apply(lambda x: f"{x:.1%}")
                        
                        st.dataframe(display_data, hide_index=True, use_container_width=True)
                        
                        # ì°¨íŠ¸ ìƒì„±
                        fig = px.bar(x=top_companies['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'], y=top_companies['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'], 
                                   orientation='h', title='ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ TOP10 (50% ì´ìƒ)',
                                   labels={'x': 'ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨', 'y': 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'})
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # í†µê³„ ì •ë³´
                        st.markdown("### ğŸ“ˆ í†µê³„ ì •ë³´")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("50% ì´ìƒ ê¸°ì—… ìˆ˜", len(high_ratio_companies))
                        with col2:
                            st.metric("ì „ì²´ ê¸°ì—… ìˆ˜", len(valid_data))
                        with col3:
                            st.metric("50% ì´ìƒ ë¹„ìœ¨", f"{len(high_ratio_companies)/len(valid_data)*100:.1f}%")
                        with col4:
                            st.metric("í‰ê·  ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨", f"{valid_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'].mean():.1%}")
                        
                        # ì—…ì¢…ë³„ ë¶„ì„
                        if 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in high_ratio_companies.columns:
                            st.markdown("### ğŸ­ ì—…ì¢…ë³„ ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ë¶„ì„")
                            
                            # ì—…ì¢…ë³„ 50% ì´ìƒ ê¸°ì—… ìˆ˜
                            sector_high_ratio = high_ratio_companies.groupby('í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜').size().reset_index(name='50%_ì´ìƒ_ê¸°ì—…ìˆ˜')
                            sector_total = valid_data.groupby('í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜').size().reset_index(name='ì „ì²´_ê¸°ì—…ìˆ˜')
                            
                            sector_analysis = sector_total.merge(sector_high_ratio, on='í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', how='left')
                            sector_analysis['50%_ì´ìƒ_ê¸°ì—…ìˆ˜'] = sector_analysis['50%_ì´ìƒ_ê¸°ì—…ìˆ˜'].fillna(0)
                            sector_analysis['ë¹„ìœ¨'] = sector_analysis['50%_ì´ìƒ_ê¸°ì—…ìˆ˜'] / sector_analysis['ì „ì²´_ê¸°ì—…ìˆ˜'] * 100
                            sector_analysis = sector_analysis.sort_values('ë¹„ìœ¨', ascending=False)
                            
                            st.dataframe(sector_analysis, hide_index=True, use_container_width=True)
                            
                            # ì—…ì¢…ë³„ ì°¨íŠ¸
                            fig = px.bar(x=sector_analysis['ë¹„ìœ¨'], y=sector_analysis['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'], 
                                       orientation='h', title='ì—…ì¢…ë³„ ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ 50% ì´ìƒ ê¸°ì—… ë¹„ìœ¨',
                                       labels={'x': '50% ì´ìƒ ê¸°ì—… ë¹„ìœ¨ (%)', 'y': 'ì—…ì¢…'})
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # ë¶„í¬ ë¶„ì„
                        st.markdown("### ğŸ“Š ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ë¶„í¬")
                        fig = px.histogram(valid_data, x='ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨', nbins=20, 
                                         title='ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ë¶„í¬')
                        # 50% ê¸°ì¤€ì„  ì¶”ê°€
                        fig.add_vline(x=0.5, line_dash="dash", line_color="red", 
                                    annotation_text="50% ê¸°ì¤€ì„ ", annotation_position="top")
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # í•´ì„ ì •ë³´
                        st.markdown("### ğŸ’¡ ë¶„ì„ í•´ì„")
                        st.info("""
                        **ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ í•´ì„:**
                        - **ë†’ì€ ë¹„ìœ¨ (50% ì´ìƒ)**: ì˜êµ¬í˜„ê¸ˆíë¦„ì´ ì „ì²´ ê¸°ì—…ê°€ì¹˜ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì´ ë†’ì€ ê¸°ì—…
                        - **ì¤‘ê°„ ë¹„ìœ¨ (30-50%)**: ì ì • ìˆ˜ì¤€ì˜ ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ì¤‘
                        - **ë‚®ì€ ë¹„ìœ¨ (30% ë¯¸ë§Œ)**: ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ì¤‘ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ê¸°ì—…
                        
                        **ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ ë†’ì€ ê¸°ì—…ì˜ íŠ¹ì§•:**
                        - ì¥ê¸°ì ì¸ ì„±ì¥ ì „ë§ì´ ì¢‹ì€ ê¸°ì—…
                        - ì•ˆì •ì ì¸ í˜„ê¸ˆíë¦„ì„ ì°½ì¶œí•˜ëŠ” ê¸°ì—…
                        - ì„±ìˆ™í•œ ì‚¬ì—… ëª¨ë¸ì„ ê°€ì§„ ê¸°ì—…
                        """)
                        
                        return True
                    else:
                        st.warning("ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.info(f"í˜„ì¬ ë°ì´í„°ì—ì„œ ê°€ì¥ ë†’ì€ ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨: {valid_data['ì˜êµ¬í˜„ê¸ˆíë¦„_ë¹„ìœ¨'].max():.1%}")
                        return True
                else:
                    st.warning("ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜ ë°ì´í„°ê°€ ìˆëŠ” ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return True
            else:
                st.subheader('ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ë¶„ì„')
                st.info("í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” 'ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜' ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.info("ì´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì¶”ê°€ì ì¸ í˜„ê¸ˆíë¦„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
                st.markdown("""
                - ì¶”ì •ê¸°ê°„ í˜„ì¬ê°€ì¹˜ / ì˜ì—…ê°€ì¹˜ ë¹„ìœ¨
                - ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°
                """)
                return True
        
        # 9. ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ê´€ë ¨ ì§ˆë¬¸ (êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ìš°ì„ )
        elif "ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±" in question or ("ë¹„ì˜ì—…ìì‚°" in question and "êµ¬ì„±" in question):
            st.info(f"ğŸ” ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹: '{question}'")
            # ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±' in df.columns:
                st.subheader('ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë¶„ì„')
                
                # ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë°ì´í„° ì •ë¦¬
                non_operating_assets = df['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±'].dropna()
                
                if not non_operating_assets.empty:
                    # ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë¹ˆë„ ë¶„ì„
                    if 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df.columns:
                        # ì—…ì¢…ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë¹ˆë„ ê³„ì‚°
                        sector_assets = df[['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±']].dropna()
                        
                        if not sector_assets.empty:
                            # ê° ì—…ì¢…ë³„ë¡œ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± í•­ëª©ë“¤ì„ ë¶„ë¦¬í•˜ê³  ë¹ˆë„ ê³„ì‚°
                            asset_frequency = {}
                            
                            for sector in sector_assets['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].unique():
                                sector_data = sector_assets[sector_assets['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'] == sector]
                                assets_list = []
                                
                                for assets in sector_data['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±']:
                                    if pd.notna(assets) and str(assets).strip() != '':
                                        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìì‚° í•­ëª©ë“¤ì„ ë¶„ë¦¬
                                        items = [item.strip() for item in str(assets).split(',')]
                                        assets_list.extend(items)
                                
                                # ë¹ˆë„ ê³„ì‚°
                                asset_counter = Counter(assets_list)
                                asset_frequency[sector] = asset_counter
                            
                            # ì „ì²´ ì—…ì¢…ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•œ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± TOP5
                            st.markdown("### ğŸ“Š ì „ì²´ ì—…ì¢… ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± TOP5")
                            
                            all_assets = []
                            for sector, counter in asset_frequency.items():
                                all_assets.extend(list(counter.elements()))
                            
                            if all_assets:
                                overall_counter = Counter(all_assets)
                                top5_overall = overall_counter.most_common(5)
                                
                                # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
                                top5_df = pd.DataFrame(top5_overall, columns=['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±', 'ë¹ˆë„'])
                                st.dataframe(top5_df, hide_index=True, use_container_width=True)
                                
                                # ì°¨íŠ¸ ìƒì„±
                                fig = px.bar(x=top5_df['ë¹ˆë„'], y=top5_df['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±'], 
                                           orientation='h', title='ì „ì²´ ì—…ì¢… ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± TOP5',
                                           labels={'x': 'ë¹ˆë„', 'y': 'ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±'})
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # ì—…ì¢…ë³„ ìƒì„¸ ë¶„ì„
                            st.markdown("### ğŸ“ˆ ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ìƒì„¸ ë¶„ì„")
                            
                            # ì—…ì¢… ì„ íƒ
                            sectors = list(asset_frequency.keys())
                            selected_sector = st.selectbox("ë¶„ì„í•  ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš”:", sectors)
                            
                            if selected_sector and selected_sector in asset_frequency:
                                sector_counter = asset_frequency[selected_sector]
                                top5_sector = sector_counter.most_common(5)
                                
                                if top5_sector:
                                    st.markdown(f"#### {selected_sector} ì—…ì¢… ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± TOP5")
                                    
                                    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
                                    sector_df = pd.DataFrame(top5_sector, columns=['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±', 'ë¹ˆë„'])
                                    st.dataframe(sector_df, hide_index=True, use_container_width=True)
                                    
                                    # ì°¨íŠ¸ ìƒì„±
                                    fig = px.bar(x=sector_df['ë¹ˆë„'], y=sector_df['ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±'], 
                                               orientation='h', title=f'{selected_sector} ì—…ì¢… ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± TOP5',
                                               labels={'x': 'ë¹ˆë„', 'y': 'ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±'})
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # í†µê³„ ì •ë³´
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("ì´ ìì‚° ìœ í˜• ìˆ˜", len(sector_counter))
                                    with col2:
                                        st.metric("ì´ ê¸°ì—… ìˆ˜", sum(sector_counter.values()))
                                    with col3:
                                        st.metric("í‰ê·  ìì‚° ìœ í˜• ìˆ˜", f"{sum(sector_counter.values())/len(sector_counter):.1f}")
                                
                                else:
                                    st.warning(f"{selected_sector} ì—…ì¢…ì˜ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ì „ì²´ í†µê³„
                            st.markdown("### ğŸ“Š ì „ì²´ í†µê³„")
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("ë¶„ì„ ì—…ì¢… ìˆ˜", len(asset_frequency))
                            with col2:
                                st.metric("ì´ ê¸°ì—… ìˆ˜", len(sector_assets))
                            with col3:
                                st.metric("ë°ì´í„° ìˆëŠ” ê¸°ì—… ìˆ˜", len(non_operating_assets))
                            with col4:
                                data_coverage = len(non_operating_assets) / len(df) * 100 if len(df) > 0 else 0
                                st.metric("ë°ì´í„° ì»¤ë²„ë¦¬ì§€", f"{data_coverage:.1f}%")
                            
                            return True
                        else:
                            st.warning("ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            return True
                    else:
                        st.warning("ì‚°ì—…ë¶„ë¥˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return True
                else:
                    st.warning("ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return True
            else:
                st.subheader('ë¹„ì˜ì—…ìì‚° ë¶„ì„')
                st.info("í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” ë¹„ì˜ì—…ìì‚° ìƒì„¸ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.info("ì´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì¶”ê°€ì ì¸ ì¬ë¬´ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
                st.markdown("""
                - ê¸°ì—…ê°€ì¹˜ (Enterprise Value)
                - ë¹„ì˜ì—…ìì‚° ì´ì•¡
                - ë¹„ì˜ì—…ìì‚° êµ¬ì„± ë‚´ì—­ (í˜„ê¸ˆì„±ìì‚°, íˆ¬ìì¦ê¶Œ, ë¶€ë™ì‚° ë“±)
                - ë¹„ì˜ì—…ìì‚° ë¹„ì¤‘ (ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„)
                """)
                return True
        
        # 10. ê³µì‹œë°œí–‰ê¸°ì—… íˆ¬ì ë§µí•‘ ë¶„ì„
        elif "íˆ¬ì" in question and ("ë§µí•‘" in question or "ë§¤í•‘" in question or "íˆ¬ìë§µ" in question):
            st.subheader('ê³µì‹œë°œí–‰ê¸°ì—… íˆ¬ì ë§µí•‘ ë¶„ì„')
            
            # íˆ¬ì ê´€ë ¨ ê±°ë˜ë§Œ í•„í„°ë§ (ì£¼ì‹ì–‘ìˆ˜, ì¶œì ë“±)
            if 'ê³µì‹œë°œí–‰_ê¸°ì—…ëª…' in df.columns and 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…' in df.columns and 'ë³´ê³ ì„œëª©ì ' in df.columns:
                # íˆ¬ì ê´€ë ¨ ë³´ê³ ì„œëª©ì  í•„í„°ë§
                investment_purposes = [
                    'íƒ€ë²•ì¸ì£¼ì‹ë°ì¶œìì–‘ìˆ˜ê²°ì •',
                    'ìœ ìƒì¦ìê²°ì •',
                    'ìœ ìƒì¦ì',
                    'ì§€ë¶„ì¦ê¶Œ'
                ]
                
                investment_data = df[df['ë³´ê³ ì„œëª©ì '].isin(investment_purposes)].copy()
                
                if not investment_data.empty:
                    # ê³µì‹œë°œí–‰ê¸°ì—…ë³„ íˆ¬ì í˜„í™©
                    st.markdown("### ğŸ“ˆ ê³µì‹œë°œí–‰ê¸°ì—…ë³„ íˆ¬ì í˜„í™©")
                    
                    # íˆ¬ì ê±´ìˆ˜ë³„ TOP ê³µì‹œë°œí–‰ê¸°ì—…
                    investment_counts = investment_data.groupby('ê³µì‹œë°œí–‰_ê¸°ì—…ëª…').agg({
                        'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…': 'count',
                        'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜': 'first'
                    }).rename(columns={'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…': 'íˆ¬ìê±´ìˆ˜'}).reset_index()
                    
                    investment_counts = investment_counts.sort_values('íˆ¬ìê±´ìˆ˜', ascending=False).head(20)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**íˆ¬ì í™œë°œí•œ ê¸°ì—… TOP20**")
                        display_investment = investment_counts[['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'íˆ¬ìê±´ìˆ˜']].copy()
                        st.dataframe(display_investment, hide_index=True, use_container_width=True)
                    
                    with col2:
                        # íˆ¬ì ê±´ìˆ˜ ì°¨íŠ¸
                        fig = px.bar(investment_counts.head(10), x='íˆ¬ìê±´ìˆ˜', y='ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 
                                   orientation='h', title='íˆ¬ì í™œë°œí•œ ê¸°ì—… TOP10')
                        fig.update_layout(yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # íˆ¬ì ë§µí•‘ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
                    st.markdown("### ğŸ”— íˆ¬ì ë§µí•‘ ë„¤íŠ¸ì›Œí¬")
                    
                    # íŠ¹ì • ê³µì‹œë°œí–‰ê¸°ì—… ì„ íƒ
                    top_investors = investment_counts.head(10)['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'].tolist()
                    selected_investor = st.selectbox("ê³µì‹œë°œí–‰ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš”:", top_investors)
                    
                    if selected_investor:
                        investor_data = investment_data[investment_data['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'] == selected_investor]
                        
                        if not investor_data.empty:
                            st.markdown(f"**{selected_investor}ì˜ íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤**")
                            
                            # íˆ¬ì ëŒ€ìƒ ë¶„ì„
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**íˆ¬ì ëŒ€ìƒ ê¸°ì—… ëª©ë¡**")
                                portfolio = investor_data[['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë³´ê³ ì„œëª©ì ', 'ë°œí–‰ì¼ì']].copy()
                                portfolio = portfolio.sort_values('ë°œí–‰ì¼ì', ascending=False)
                                st.dataframe(portfolio, hide_index=True, use_container_width=True)
                            
                            with col2:
                                st.markdown("**íˆ¬ì ëŒ€ìƒ ì—…ì¢… ë¶„í¬**")
                                sector_distribution = investor_data['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].value_counts()
                                fig = px.pie(values=sector_distribution.values, 
                                           names=sector_distribution.index,
                                           title=f'{selected_investor}ì˜ íˆ¬ì ì—…ì¢… ë¶„í¬')
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # íˆ¬ì í†µê³„
                            st.markdown(f"**{selected_investor}ì˜ íˆ¬ì í†µê³„**")
                            col_stat1, col_stat2, col_stat3 = st.columns(3)
                            
                            with col_stat1:
                                st.metric("ì´ íˆ¬ì ê±´ìˆ˜", len(investor_data))
                            with col_stat2:
                                st.metric("íˆ¬ì ëŒ€ìƒ ê¸°ì—… ìˆ˜", investor_data['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'].nunique())
                            with col_stat3:
                                st.metric("íˆ¬ì ì—…ì¢… ìˆ˜", investor_data['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].nunique())
                    
                    # í•´ì„ ê°€ì´ë“œ
                    st.markdown("### ğŸ’¡ íˆ¬ì ë§µí•‘ ë¶„ì„ í•´ì„ ê°€ì´ë“œ")
                    st.info("""
                    **íˆ¬ì ë§µí•‘ ë¶„ì„ í™œìš©ë²•:**
                    
                    1. **íˆ¬ì í™œë°œë„**: ì–´ë–¤ ê¸°ì—…ì´ ì ê·¹ì ìœ¼ë¡œ íˆ¬ìí•˜ëŠ”ì§€ í™•ì¸
                    2. **í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„**: ì„ íƒëœ ê¸°ì—…ì˜ íˆ¬ì ëŒ€ìƒê³¼ ì—…ì¢… ë‹¤ì–‘ì„±
                    3. **íˆ¬ì íŒ¨í„´**: ê¸°ì—…ë³„ íˆ¬ì ì „ëµê³¼ ì„ í˜¸ ì—…ì¢… íŒŒì•…
                    
                    **ì£¼ìš” íˆ¬ì ìœ í˜•:**
                    - **íƒ€ë²•ì¸ì£¼ì‹ë°ì¶œìì–‘ìˆ˜**: ë‹¤ë¥¸ íšŒì‚¬ ì§€ë¶„ ì·¨ë“
                    - **ìœ ìƒì¦ì**: ì‹ ì£¼ ë°œí–‰ì„ í†µí•œ ìê¸ˆ ì¡°ë‹¬
                    """)
                    
                else:
                    st.warning("íˆ¬ì ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("í•„ìš”í•œ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            
            return True

        # 11. ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ ë¶„ì„ (ë³´ê³ ì„œëª©ì  ê¸°ë°˜)
        elif "ì—…ì¢…" in question and ("ì–‘ìˆ˜" in question or "ì–‘ë„" in question or "ê±°ë˜" in question):
            st.subheader('ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ ë¶„ì„')
            
            # ê³µì‹œë°œí–‰ ê¸°ì—… ì—…ì¢…ê³¼ í‰ê°€ëŒ€ìƒê¸°ì—… ì—…ì¢… ê°„ì˜ ê±°ë˜ ê´€ê³„ ë¶„ì„
            if 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df.columns and 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df.columns and 'ë³´ê³ ì„œëª©ì ' in df.columns:
                # ì—…ì¢… ê°„ ê±°ë˜ ë°ì´í„° ì •ë¦¬ (ë³´ê³ ì„œëª©ì  í¬í•¨)
                transaction_data = df[['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë³´ê³ ì„œëª©ì ', 'ë°œí–‰ì¼ì']].dropna()
                
                if not transaction_data.empty:
                    # ê±°ë˜ ëª©ì ë³„ ë¶„ì„
                    st.markdown("### ğŸ¯ ê±°ë˜ ëª©ì ë³„ ë¶„ì„")
                    
                    # ê±°ë˜ ëª©ì ë³„ ê±´ìˆ˜
                    purpose_counts = transaction_data['ë³´ê³ ì„œëª©ì '].value_counts()
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**ê±°ë˜ ëª©ì ë³„ ê±´ìˆ˜ TOP10**")
                        purpose_df = purpose_counts.head(10).reset_index()
                        purpose_df.columns = ['ê±°ë˜ëª©ì ', 'ê±´ìˆ˜']
                        st.dataframe(purpose_df, hide_index=True, use_container_width=True)
                    
                    with col2:
                        # ê±°ë˜ ëª©ì ë³„ íŒŒì´ ì°¨íŠ¸
                        fig = px.pie(values=purpose_counts.head(8).values, 
                                   names=purpose_counts.head(8).index,
                                   title='ì£¼ìš” ê±°ë˜ ëª©ì  ë¶„í¬')
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # ì—…ì¢… ê°„ ê±°ë˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                    st.markdown("### ğŸ“Š ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤")
                    
                    # ê³µì‹œë°œí–‰ ì—…ì¢… â†’ í‰ê°€ëŒ€ìƒ ì—…ì¢… ê±°ë˜ ë¹ˆë„ ê³„ì‚°
                    sector_transactions = transaction_data.groupby(['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜']).size().reset_index(name='ê±°ë˜ê±´ìˆ˜')
                    
                    # í”¼ë²— í…Œì´ë¸” ìƒì„±
                    pivot_table = sector_transactions.pivot(index='ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 
                                                          columns='í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 
                                                          values='ê±°ë˜ê±´ìˆ˜').fillna(0)
                    
                    # ê±°ë˜ê±´ìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                    pivot_table = pivot_table.sort_index()
                    pivot_table = pivot_table.sort_index(axis=1)
                    
                    st.dataframe(pivot_table.astype(int), use_container_width=True)
                    
                    # íˆíŠ¸ë§µ ì°¨íŠ¸ ìƒì„±
                    fig = go.Figure(data=go.Heatmap(
                        z=pivot_table.values,
                        x=pivot_table.columns,
                        y=pivot_table.index,
                        colorscale='Blues',
                        text=pivot_table.values,
                        texttemplate="%{text}",
                        textfont={"size": 10},
                        hoverongaps=False
                    ))
                    
                    fig.update_layout(
                        title='ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ íˆíŠ¸ë§µ',
                        xaxis_title='í‰ê°€ëŒ€ìƒê¸°ì—… ì—…ì¢…',
                        yaxis_title='ê³µì‹œë°œí–‰ ê¸°ì—… ì—…ì¢…',
                        width=800,
                        height=600
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ìƒìœ„ ê±°ë˜ ê´€ê³„ ë¶„ì„
                    st.markdown("### ğŸ” ì£¼ìš” ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ TOP10")
                    
                    # ê±°ë˜ê±´ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ
                    top_transactions = sector_transactions.sort_values('ê±°ë˜ê±´ìˆ˜', ascending=False).head(10)
                    
                    # ê±°ë˜ ê´€ê³„ ì„¤ëª… ì¶”ê°€
                    top_transactions['ê±°ë˜ê´€ê³„'] = top_transactions['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'] + ' â†’ ' + top_transactions['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜']
                    
                    display_data = top_transactions[['ê±°ë˜ê´€ê³„', 'ê±°ë˜ê±´ìˆ˜']].copy()
                    st.dataframe(display_data, hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(top_transactions, x='ê±°ë˜ê±´ìˆ˜', y='ê±°ë˜ê´€ê³„', 
                               orientation='h', title='ì£¼ìš” ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ TOP10',
                               labels={'ê±°ë˜ê±´ìˆ˜': 'ê±°ë˜ ê±´ìˆ˜', 'ê±°ë˜ê´€ê³„': 'ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„'})
                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # í†µê³„ ì •ë³´
                    st.markdown("### ğŸ“ˆ ê±°ë˜ ê´€ê³„ í†µê³„")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ì´ ê±°ë˜ ê±´ìˆ˜", len(transaction_data))
                    with col2:
                        st.metric("ê³µì‹œë°œí–‰ ì—…ì¢… ìˆ˜", len(transaction_data['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].unique()))
                    with col3:
                        st.metric("í‰ê°€ëŒ€ìƒ ì—…ì¢… ìˆ˜", len(transaction_data['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].unique()))
                    with col4:
                        st.metric("ì—…ì¢… ê°„ ê±°ë˜ ìŒ", len(sector_transactions))
                    
                    # ê±°ë˜ ëª©ì ë³„ ì—…ì¢… ë¶„ì„
                    st.markdown("### ğŸ“ˆ ê±°ë˜ ëª©ì ë³„ ì—…ì¢… ë¶„ì„")
                    
                    # ì£¼ìš” ê±°ë˜ ëª©ì  ì„ íƒ
                    major_purposes = purpose_counts.head(5).index.tolist()
                    selected_purpose = st.selectbox("ê±°ë˜ ëª©ì ì„ ì„ íƒí•˜ì„¸ìš”:", major_purposes)
                    
                    if selected_purpose:
                        purpose_data = transaction_data[transaction_data['ë³´ê³ ì„œëª©ì '] == selected_purpose]
                        
                        if not purpose_data.empty:
                            st.markdown(f"**{selected_purpose} ê±°ë˜ì˜ ì—…ì¢…ë³„ ë¶„ì„**")
                            
                            # ì—…ì¢…ë³„ ê±°ë˜ í˜„í™©
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**ê³µì‹œë°œí–‰ ì—…ì¢…ë³„ í˜„í™©**")
                                issuing_counts = purpose_data['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].value_counts().head(10)
                                issuing_df = issuing_counts.reset_index()
                                issuing_df.columns = ['ì—…ì¢…', 'ê±´ìˆ˜']
                                st.dataframe(issuing_df, hide_index=True, use_container_width=True)
                            
                            with col2:
                                st.markdown("**í‰ê°€ëŒ€ìƒ ì—…ì¢…ë³„ í˜„í™©**")
                                target_counts = purpose_data['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].value_counts().head(10)
                                target_df = target_counts.reset_index()
                                target_df.columns = ['ì—…ì¢…', 'ê±´ìˆ˜']
                                st.dataframe(target_df, hide_index=True, use_container_width=True)
                            
                            # ì—…ì¢… ê°„ ì¡°í•© ë¶„ì„
                            st.markdown(f"**{selected_purpose} ê±°ë˜ì˜ ì—…ì¢… ê°„ ì¡°í•© TOP10**")
                            purpose_combinations = purpose_data.groupby(['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜']).size().reset_index(name='ê±°ë˜ê±´ìˆ˜')
                            purpose_combinations['ê±°ë˜ì¡°í•©'] = purpose_combinations['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'] + ' â†’ ' + purpose_combinations['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜']
                            purpose_combinations = purpose_combinations.sort_values('ê±°ë˜ê±´ìˆ˜', ascending=False).head(10)
                            
                            combo_display = purpose_combinations[['ê±°ë˜ì¡°í•©', 'ê±°ë˜ê±´ìˆ˜']].copy()
                            st.dataframe(combo_display, hide_index=True, use_container_width=True)
                            
                            # ì°¨íŠ¸ ìƒì„±
                            if len(purpose_combinations) > 0:
                                fig = px.bar(purpose_combinations, x='ê±°ë˜ê±´ìˆ˜', y='ê±°ë˜ì¡°í•©', 
                                           orientation='h', title=f'{selected_purpose} ê±°ë˜ì˜ ì—…ì¢… ê°„ ì¡°í•© TOP10')
                                fig.update_layout(yaxis={'categoryorder':'total ascending'})
                                st.plotly_chart(fig, use_container_width=True)
                    
                    # íŠ¹ì • ì—…ì¢… ë¶„ì„
                    st.markdown("### ğŸ¯ íŠ¹ì • ì—…ì¢… ê±°ë˜ ë¶„ì„")
                    
                    # ê³µì‹œë°œí–‰ ì—…ì¢… ì„ íƒ
                    issuing_sectors = sorted(transaction_data['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].unique())
                    selected_issuing_sector = st.selectbox("ê³µì‹œë°œí–‰ ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš”:", issuing_sectors)
                    
                    if selected_issuing_sector:
                        # ì„ íƒëœ ê³µì‹œë°œí–‰ ì—…ì¢…ì˜ ê±°ë˜ í˜„í™©
                        selected_data = transaction_data[transaction_data['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'] == selected_issuing_sector]
                        
                        st.markdown(f"**{selected_issuing_sector} ì—…ì¢…ì˜ ê±°ë˜ í˜„í™©:**")
                        
                        # í‰ê°€ëŒ€ìƒ ì—…ì¢…ë³„ ê±°ë˜ ê±´ìˆ˜
                        target_sector_counts = selected_data.groupby('í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜').size().reset_index(name='ê±°ë˜ê±´ìˆ˜')
                        target_sector_counts = target_sector_counts.sort_values('ê±°ë˜ê±´ìˆ˜', ascending=False)
                        
                        st.dataframe(target_sector_counts, hide_index=True, use_container_width=True)
                        
                        # ì°¨íŠ¸ ìƒì„±
                        if len(target_sector_counts) > 0:
                            fig = px.pie(target_sector_counts, values='ê±°ë˜ê±´ìˆ˜', names='í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 
                                       title=f'{selected_issuing_sector} ì—…ì¢…ì˜ í‰ê°€ëŒ€ìƒ ì—…ì¢…ë³„ ê±°ë˜ ë¹„ì¤‘')
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # ê±°ë˜ ëª©ì ë³„ ë¶„ì„
                        st.markdown(f"**{selected_issuing_sector} ì—…ì¢…ì˜ ê±°ë˜ ëª©ì ë³„ í˜„í™©:**")
                        purpose_in_sector = selected_data['ë³´ê³ ì„œëª©ì '].value_counts()
                        purpose_sector_df = purpose_in_sector.reset_index()
                        purpose_sector_df.columns = ['ê±°ë˜ëª©ì ', 'ê±´ìˆ˜']
                        st.dataframe(purpose_sector_df, hide_index=True, use_container_width=True)
                        
                        # êµ¬ì²´ì ì¸ ê±°ë˜ ë‚´ì—­
                        st.markdown(f"**{selected_issuing_sector} ì—…ì¢…ì˜ êµ¬ì²´ì ì¸ ê±°ë˜ ë‚´ì—­:**")
                        display_transactions = selected_data[['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë³´ê³ ì„œëª©ì ', 'ë°œí–‰ì¼ì']].copy()
                        display_transactions = display_transactions.sort_values('ë°œí–‰ì¼ì', ascending=False)
                        st.dataframe(display_transactions, hide_index=True, use_container_width=True)
                    
                    # í•´ì„ ê°€ì´ë“œ
                    st.markdown("### ğŸ’¡ ë¶„ì„ í•´ì„ ê°€ì´ë“œ")
                    st.info("""
                    **ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ ë¶„ì„ í•´ì„:**
                    
                    1. **ê±°ë˜ ëª©ì ë³„ ë¶„ì„**: ì–‘ìˆ˜, ì–‘ë„, í•©ë³‘ ë“± ê±°ë˜ ìœ í˜•ë³„ íŠ¸ë Œë“œ íŒŒì•…
                    2. **ì—…ì¢…ë³„ ê±°ë˜ íŒ¨í„´**: íŠ¹ì • ì—…ì¢…ì´ ì£¼ë¡œ ì–´ë–¤ ê±°ë˜ì— ì°¸ì—¬í•˜ëŠ”ì§€ í™•ì¸
                    3. **ì—…ì¢… ê°„ ê´€ê³„**: ì–´ë–¤ ì—…ì¢… ì¡°í•©ì—ì„œ ê±°ë˜ê°€ í™œë°œí•œì§€ ë¶„ì„
                    4. **ì‹œì¥ ë™í–¥**: ê±°ë˜ ëª©ì ê³¼ ì—…ì¢… ì¡°í•©ìœ¼ë¡œ M&A ì‹œì¥ íŠ¸ë Œë“œ íŒŒì•…
                    
                    **ì£¼ìš” ê±°ë˜ ìœ í˜•:**
                    - **íƒ€ë²•ì¸ì£¼ì‹ë°ì¶œìì–‘ìˆ˜ê²°ì •**: ë‹¤ë¥¸ íšŒì‚¬ì˜ ì£¼ì‹ì´ë‚˜ ì§€ë¶„ì„ ì‚¬ë“¤ì´ëŠ” ê±°ë˜
                    - **íšŒì‚¬í•©ë³‘ê²°ì •**: ë‘ íšŒì‚¬ê°€ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê±°ë˜
                    - **íƒ€ë²•ì¸ì£¼ì‹ë°ì¶œìì–‘ë„ê²°ì •**: ë³´ìœ í•˜ê³  ìˆë˜ ì£¼ì‹ì´ë‚˜ ì§€ë¶„ì„ íŒŒëŠ” ê±°ë˜
                    - **ì˜ì—…ì–‘ìˆ˜/ì–‘ë„ê²°ì •**: ì‚¬ì—… ë¶€ë¬¸ì„ ì‚¬ê³ íŒŒëŠ” ê±°ë˜
                    
                    **í™œìš© ë°©ì•ˆ:**
                    - M&A ì‹œì¥ ë¶„ì„ ë° ì˜ˆì¸¡
                    - ì—…ì¢…ë³„ íˆ¬ì ì „ëµ ìˆ˜ë¦½
                    - ê±°ë˜ íŠ¸ë Œë“œ íŒŒì•…
                    - ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ê¸°íšŒ ë°œê²¬
                    """)
                    
                else:
                    st.warning("ì—…ì¢… ê°„ ê±°ë˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("í•„ìš”í•œ ì»¬ëŸ¼(ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜, í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜)ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")

        elif "ê¸°ì—…ê°€ì¹˜" in question and "ë¹„ì˜ì—…ìì‚°" in question and "ë§ì€" in question:
            st.subheader('ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚° ë¶„ì„ (NOA/Enterprise Value)')
            
            # NOA / Enterprise Value ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'NOA / Enterprise Value' in df.columns:
                # NOA / Enterprise Value ë°ì´í„° ì •ë¦¬
                noa_data = df[['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'NOA / Enterprise Value']].dropna(subset=['NOA / Enterprise Value'])
                
                if not noa_data.empty:
                    # NOA / Enterprise Value ê°’ì´ ë†’ì€ ìƒìœ„ ê¸°ì—…ë“¤ (ë¹„ì˜ì—…ìì‚° ë¹„ì¤‘ì´ ë†’ì€ ê¸°ì—…ë“¤)
                    st.markdown("### ğŸ“Š ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚° ë¹„ì¤‘ì´ ë†’ì€ ê¸°ì—… TOP10")
                    
                    # ìƒìœ„ 10ê°œ ê¸°ì—… ì„ íƒ
                    top_noa = noa_data.sort_values('NOA / Enterprise Value', ascending=False).head(10)
                    
                    # ë°ì´í„° í‘œì‹œ
                    st.dataframe(top_noa, hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = px.bar(x=top_noa['NOA / Enterprise Value'], y=top_noa['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'], 
                               orientation='h', title='ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚° ë¹„ì¤‘ TOP10',
                               labels={'x': 'NOA / Enterprise Value ë¹„ìœ¨', 'y': 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'})
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # í†µê³„ ì •ë³´
                    st.markdown("### ğŸ“ˆ í†µê³„ ì •ë³´")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("í‰ê·  NOA/EV ë¹„ìœ¨", f"{noa_data['NOA / Enterprise Value'].mean():.3f}")
                    with col2:
                        st.metric("ì¤‘ì•™ê°’ NOA/EV ë¹„ìœ¨", f"{noa_data['NOA / Enterprise Value'].median():.3f}")
                    with col3:
                        st.metric("ìµœëŒ€ê°’", f"{noa_data['NOA / Enterprise Value'].max():.3f}")
                    with col4:
                        st.metric("ë°ì´í„° ìˆëŠ” ê¸°ì—… ìˆ˜", len(noa_data))
                    
                    # ì—…ì¢…ë³„ ë¶„ì„
                    if 'í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in noa_data.columns:
                        st.markdown("### ğŸ­ ì—…ì¢…ë³„ NOA/Enterprise Value ë¶„ì„")
                        
                        # ì—…ì¢…ë³„ í‰ê·  ê³„ì‚°
                        sector_avg = noa_data.groupby('í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜')['NOA / Enterprise Value'].agg(['mean', 'count']).reset_index()
                        sector_avg = sector_avg[sector_avg['count'] >= 2]  # 2ê°œ ì´ìƒ ë°ì´í„°ê°€ ìˆëŠ” ì—…ì¢…ë§Œ
                        sector_avg = sector_avg.sort_values('mean', ascending=False)
                        
                        if not sector_avg.empty:
                            st.dataframe(sector_avg.rename(columns={'mean': 'í‰ê·  NOA/EV ë¹„ìœ¨', 'count': 'ê¸°ì—… ìˆ˜'}), 
                                       hide_index=True, use_container_width=True)
                            
                            # ì—…ì¢…ë³„ ì°¨íŠ¸
                            fig = px.bar(x=sector_avg['mean'], y=sector_avg['í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'], 
                                       orientation='h', title='ì—…ì¢…ë³„ í‰ê·  NOA/Enterprise Value ë¹„ìœ¨',
                                       labels={'x': 'í‰ê·  NOA/EV ë¹„ìœ¨', 'y': 'ì—…ì¢…'})
                            st.plotly_chart(fig, use_container_width=True)
                    
                    # ë¶„í¬ ë¶„ì„
                    st.markdown("### ğŸ“Š NOA/Enterprise Value ë¶„í¬")
                    fig = px.histogram(noa_data, x='NOA / Enterprise Value', nbins=20, 
                                     title='NOA/Enterprise Value ë¶„í¬')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # í•´ì„ ì •ë³´
                    st.markdown("### ğŸ’¡ ë¶„ì„ í•´ì„")
                    st.info("""
                    **NOA/Enterprise Value ë¹„ìœ¨ í•´ì„:**
                    - **ë†’ì€ ë¹„ìœ¨ (0.5 ì´ìƒ)**: ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚°ì´ ë§ì€ ê¸°ì—…
                    - **ì¤‘ê°„ ë¹„ìœ¨ (0.2-0.5)**: ì ì • ìˆ˜ì¤€ì˜ ë¹„ì˜ì—…ìì‚° ë³´ìœ 
                    - **ë‚®ì€ ë¹„ìœ¨ (0.2 ë¯¸ë§Œ)**: ë¹„ì˜ì—…ìì‚°ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ê¸°ì—…
                    
                    **ë¹„ì˜ì—…ìì‚°ì´ ë§ì€ ê¸°ì—…ì˜ íŠ¹ì§•:**
                    - í˜„ê¸ˆì„±ìì‚°, íˆ¬ìì¦ê¶Œ, ë¶€ë™ì‚° ë“± ë¹„ì˜ì—…ìš© ìì‚°ì„ ë§ì´ ë³´ìœ 
                    - ì˜ì—…í™œë™ê³¼ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ëŠ” ìì‚°ì˜ ë¹„ì¤‘ì´ ë†’ìŒ
                    """)
                    
                    return True
                else:
                    st.warning("NOA / Enterprise Value ë°ì´í„°ê°€ ìˆëŠ” ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return True
            else:
                st.subheader('ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚° ë¶„ì„')
                st.info("í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” NOA / Enterprise Value ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.info("ì´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì¶”ê°€ì ì¸ ì¬ë¬´ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
                st.markdown("""
                - ê¸°ì—…ê°€ì¹˜ (Enterprise Value)
                - ë¹„ì˜ì—…ìì‚° ì´ì•¡ (NOA)
                - NOA / Enterprise Value ë¹„ìœ¨
                """)
                st.info("ğŸ’¡ ëŒ€ì‹  'ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±ë‚´ì—­' ë¶„ì„ì„ í†µí•´ ë¹„ì˜ì—…ìì‚°ì˜ êµ¬ì„± ìš”ì†Œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                return True
        
        # 11. íŠ¹ì • ì—°ë„ + ì‚°ì—… í‰ê·  WACC
        elif any(year in question for year in ['2023', '2022', '2024', '2025']) and "wacc" in question_lower and "í‰ê· " in question:
            # ì—°ë„ ì¶”ì¶œ
            import re
            year_match = re.search(r'(202[0-9])', question)
            if year_match:
                year = int(year_match.group(1))
                start_date = pd.Timestamp(f'{year}-01-01')
                end_date = pd.Timestamp(f'{year}-12-31')
                
                # ì‚°ì—… í‚¤ì›Œë“œ ì¶”ì¶œ
                sector_keywords = ['í—¬ìŠ¤ì¼€ì–´', 'ì œì¡°', 'ì œì¡°ì—…', 'ê¸ˆìœµ', 'ê¸ˆìœµì—…', 'IT', 'ë°”ì´ì˜¤', 'ê²Œì„', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ì†Œë¹„ì¬']
                sector = None
                for keyword in sector_keywords:
                    if keyword in question:
                        sector = keyword
                        break
                
                # ë‚ ì§œ í•„í„°ë§
                if 'ë°œí–‰ì¼ì' in df.columns:
                    df_filtered = df[(df['ë°œí–‰ì¼ì'] >= start_date) & (df['ë°œí–‰ì¼ì'] <= end_date)]
                else:
                    df_filtered = df
                
                # ì‚°ì—… í•„í„°ë§
                if sector and 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df_filtered.columns:
                    df_filtered = df_filtered[df_filtered['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].str.contains(sector, na=False)]
                
                if 'WACC' in df_filtered.columns:
                    wacc_values = pd.to_numeric(df_filtered['WACC'], errors='coerce').dropna()
                    
                    if len(wacc_values) > 0:
                        st.subheader(f'{year}ë…„ {sector if sector else "ì „ì²´"} ì—…ì¢… WACC ë¶„ì„')
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric('í‰ê·  WACC', f'{wacc_values.mean() * 100:.2f}%')
                        with col2:
                            st.metric('ì¤‘ì•™ê°’ WACC', f'{wacc_values.median() * 100:.2f}%')
                        with col3:
                            st.metric('í‘œì¤€í¸ì°¨', f'{wacc_values.std() * 100:.2f}%')
                        with col4:
                            st.metric('í‘œë³¸ìˆ˜', len(wacc_values))
                        
                        # ë¶„í¬ ì°¨íŠ¸
                        fig = px.histogram(x=wacc_values * 100, nbins=20, title=f'{year}ë…„ {sector if sector else "ì „ì²´"} ì—…ì¢… WACC ë¶„í¬')
                        fig.update_layout(xaxis_title='WACC (%)')
                        st.plotly_chart(fig, use_container_width=True)
                        
                        return True
                    else:
                        st.warning(f"{year}ë…„ {sector if sector else 'ì „ì²´'} ì—…ì¢…ì˜ WACC ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return True
        
        # 12. ì—°ë„ë³„ ì£¼ìš”í†µê³„
        elif any(year in question for year in ['2022', '2023', '2024', '2025']) and ("ì£¼ìš”í†µê³„" in question or "í†µê³„" in question and "ì—°ë„ë³„" in question):
            import re
            year_match = re.search(r'(202[0-9])', question)
            if year_match:
                year = int(year_match.group(1))
                start_date = pd.Timestamp(f'{year}-01-01')
                end_date = pd.Timestamp(f'{year}-12-31')
                
                # ë‚ ì§œ í•„í„°ë§
                if 'ë°œí–‰ì¼ì' in df.columns:
                    df['ë°œí–‰ì¼ì'] = pd.to_datetime(df['ë°œí–‰ì¼ì'], errors='coerce')
                    df_filtered = df[(df['ë°œí–‰ì¼ì'] >= start_date) & (df['ë°œí–‰ì¼ì'] <= end_date)]
                else:
                    df_filtered = df
                
                if len(df_filtered) == 0:
                    st.warning(f"{year}ë…„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return True
                
                st.subheader(f'{year}ë…„ ì£¼ìš” í†µê³„')
                
                # 1. ê¸°ë³¸ í†µê³„
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric('ì´ ë°œí–‰ ê±´ìˆ˜', f'{len(df_filtered):,}ê±´')
                with col2:
                    if 'ê³µì‹œë°œí–‰_ê¸°ì—…ëª…' in df_filtered.columns:
                        unique_companies = df_filtered['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'].nunique()
                        st.metric('ê³µì‹œë°œí–‰ ê¸°ì—… ìˆ˜', f'{unique_companies:,}ê°œ')
                with col3:
                    if 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…' in df_filtered.columns:
                        unique_targets = df_filtered['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'].nunique()
                        st.metric('í‰ê°€ëŒ€ìƒ ê¸°ì—… ìˆ˜', f'{unique_targets:,}ê°œ')
                with col4:
                    if 'í‰ê°€ë²•ì¸' in df_filtered.columns:
                        unique_firms = df_filtered['í‰ê°€ë²•ì¸'].nunique()
                        st.metric('í‰ê°€ë²•ì¸ ìˆ˜', f'{unique_firms:,}ê°œ')
                
                st.markdown("---")
                
                # 2. WACC í†µê³„
                if 'WACC' in df_filtered.columns:
                    wacc_values = pd.to_numeric(df_filtered['WACC'], errors='coerce').dropna()
                    if len(wacc_values) > 0:
                        st.markdown("### ğŸ“Š WACC í†µê³„")
                        col1, col2, col3, col4, col5 = st.columns(5)
                        with col1:
                            st.metric('í‰ê· ', f'{wacc_values.mean() * 100:.2f}%')
                        with col2:
                            st.metric('ì¤‘ì•™ê°’', f'{wacc_values.median() * 100:.2f}%')
                        with col3:
                            st.metric('ìµœì†Œê°’', f'{wacc_values.min() * 100:.2f}%')
                        with col4:
                            st.metric('ìµœëŒ€ê°’', f'{wacc_values.max() * 100:.2f}%')
                        with col5:
                            st.metric('í‘œì¤€í¸ì°¨', f'{wacc_values.std() * 100:.2f}%')
                
                st.markdown("---")
                
                # 3. ì—…ì¢…ë³„ ë¶„í¬
                if 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df_filtered.columns:
                    st.markdown("### ğŸ­ ì—…ì¢…ë³„ ë¶„í¬ (TOP 10)")
                    sector_counts = df_filtered['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].value_counts().head(10)
                    sector_df = pd.DataFrame({
                        'ì—…ì¢…': sector_counts.index,
                        'ê±´ìˆ˜': sector_counts.values
                    })
                    st.dataframe(sector_df, hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸
                    fig = px.bar(sector_df, x='ì—…ì¢…', y='ê±´ìˆ˜', 
                                title=f'{year}ë…„ ì—…ì¢…ë³„ ë°œí–‰ ê±´ìˆ˜ (TOP 10)')
                    fig.update_layout(xaxis={'tickangle': 45})
                    st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("---")
                
                # 4. ë©€í‹°í”Œ í†µê³„
                st.markdown("### ğŸ’° ë©€í‹°í”Œ ì¤‘ì•™ê°’")
                multiples = ['EV/EBITDA', 'EV/Sales', 'PER', 'PSR']
                available_multiples = [m for m in multiples if m in df_filtered.columns]
                
                if available_multiples:
                    multiple_stats = []
                    for multiple in available_multiples:
                        values = pd.to_numeric(df_filtered[multiple], errors='coerce').dropna()
                        if len(values) > 0:
                            multiple_stats.append({
                                'ì§€í‘œ': multiple,
                                'ì¤‘ì•™ê°’': values.median(),
                                'í‰ê· ': values.mean(),
                                'í‘œë³¸ìˆ˜': len(values)
                            })
                    
                    if multiple_stats:
                        multiple_df = pd.DataFrame(multiple_stats)
                        st.dataframe(multiple_df, hide_index=True, use_container_width=True)
                else:
                    st.info("ë©€í‹°í”Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                st.markdown("---")
                
                # 5. í‰ê°€ë²•ì¸ë³„ í™œë™ëŸ‰
                if 'í‰ê°€ë²•ì¸' in df_filtered.columns:
                    st.markdown("### ğŸ¢ í‰ê°€ë²•ì¸ë³„ í™œë™ëŸ‰ (TOP 5)")
                    firm_counts = df_filtered['í‰ê°€ë²•ì¸'].value_counts().head(5)
                    firm_df = pd.DataFrame({
                        'í‰ê°€ë²•ì¸': firm_counts.index,
                        'ê±´ìˆ˜': firm_counts.values
                    })
                    st.dataframe(firm_df, hide_index=True, use_container_width=True)
                    
                    # ì°¨íŠ¸
                    fig = px.bar(firm_df, x='í‰ê°€ë²•ì¸', y='ê±´ìˆ˜',
                                title=f'{year}ë…„ í‰ê°€ë²•ì¸ë³„ í™œë™ëŸ‰ (TOP 5)')
                    fig.update_layout(xaxis={'tickangle': 45})
                    st.plotly_chart(fig, use_container_width=True)
                
                st.markdown("---")
                
                # 6. ì›”ë³„ ë°œí–‰ ì¶”ì´
                if 'ë°œí–‰ì¼ì' in df_filtered.columns:
                    st.markdown("### ğŸ“… ì›”ë³„ ë°œí–‰ ì¶”ì´")
                    df_monthly = df_filtered.copy()
                    df_monthly = df_monthly.copy()  # SettingWithCopyWarning ë°©ì§€
                    df_monthly.loc[:, 'ì›”'] = df_monthly['ë°œí–‰ì¼ì'].dt.to_period('M').astype(str)
                    monthly_counts = df_monthly['ì›”'].value_counts().sort_index()
                    monthly_df = pd.DataFrame({
                        'ì›”': monthly_counts.index,
                        'ê±´ìˆ˜': monthly_counts.values
                    })
                    
                    fig = px.line(monthly_df, x='ì›”', y='ê±´ìˆ˜',
                                 title=f'{year}ë…„ ì›”ë³„ ë°œí–‰ ì¶”ì´',
                                 markers=True)
                    fig.update_layout(xaxis={'tickangle': 45})
                    st.plotly_chart(fig, use_container_width=True)
                
                return True
        
        # 13. ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œ ë¶„ì„
        elif "íŠ¸ë Œë“œ" in question and "wacc" in question_lower and ("ì—°ë„ë³„" in question or "ì‚°ì—…ë³„" in question):
            st.subheader('ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œ ë¶„ì„')
            
            # ë¶„ì„í•  ì—°ë„ ëª©ë¡
            years = [2022, 2023, 2024, 2025]
            
            # ë¶„ì„í•  ì‚°ì—… ëª©ë¡
            sectors = ['ê¸ˆìœµ', 'ê¸ˆìœµì—…', 'ì†Œë¹„ì¬', 'í—¬ìŠ¤ì¼€ì–´', 'IT', 'ì œì¡°', 'ì œì¡°ì—…', 'ë°”ì´ì˜¤']
            
            # ì—°ë„ë³„ ì‚°ì—…ë³„ WACC ë°ì´í„° ìˆ˜ì§‘
            trend_data = []
            
            for year in years:
                start_date = pd.Timestamp(f'{year}-01-01')
                end_date = pd.Timestamp(f'{year}-12-31')
                
                # ë‚ ì§œ í•„í„°ë§
                if 'ë°œí–‰ì¼ì' in df.columns:
                    df['ë°œí–‰ì¼ì'] = pd.to_datetime(df['ë°œí–‰ì¼ì'], errors='coerce')
                    df_year = df[(df['ë°œí–‰ì¼ì'] >= start_date) & (df['ë°œí–‰ì¼ì'] <= end_date)]
                else:
                    df_year = df
                
                for sector in sectors:
                    # ì‚°ì—… í•„í„°ë§
                    if 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜' in df_year.columns:
                        df_sector = df_year[df_year['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].str.contains(sector, na=False)]
                    else:
                        df_sector = df_year
                    
                    # WACC ê°’ ì¶”ì¶œ
                    if 'WACC' in df_sector.columns:
                        wacc_values = pd.to_numeric(df_sector['WACC'], errors='coerce').dropna()
                        if len(wacc_values) > 0:
                            trend_data.append({
                                'ì—°ë„': year,
                                'ì‚°ì—…': sector,
                                'í‰ê· _WACC': wacc_values.mean() * 100,
                                'ì¤‘ì•™ê°’_WACC': wacc_values.median() * 100,
                                'í‘œë³¸ìˆ˜': len(wacc_values)
                            })
            
            if trend_data:
                trend_df = pd.DataFrame(trend_data)
                
                # ì‚°ì—…ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
                st.markdown("### ğŸ“Š ì—°ë„ë³„ ì‚°ì—…ë³„ WACC í‰ê· ")
                
                # í”¼ë²— í…Œì´ë¸” ìƒì„± (ì—°ë„ x ì‚°ì—…)
                pivot_avg = trend_df.pivot_table(
                    index='ì‚°ì—…', 
                    columns='ì—°ë„', 
                    values='í‰ê· _WACC', 
                    aggfunc='mean'
                )
                
                # í‘œë³¸ìˆ˜ê°€ 0ì¸ ê²½ìš° ì œì™¸
                pivot_avg = pivot_avg.fillna(0)
                
                st.dataframe(pivot_avg.round(2), use_container_width=True)
                
                # ë¼ì¸ ì°¨íŠ¸ ìƒì„± (ì‚°ì—…ë³„ íŠ¸ë Œë“œ)
                st.markdown("### ğŸ“ˆ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œ (ë¼ì¸ ì°¨íŠ¸)")
                
                # ê° ì‚°ì—…ë³„ë¡œ ë¼ì¸ ì°¨íŠ¸ ìƒì„±
                fig = go.Figure()
                
                for sector in trend_df['ì‚°ì—…'].unique():
                    sector_data = trend_df[trend_df['ì‚°ì—…'] == sector].sort_values('ì—°ë„')
                    if len(sector_data) > 0:
                        fig.add_trace(go.Scatter(
                            x=sector_data['ì—°ë„'],
                            y=sector_data['í‰ê· _WACC'],
                            mode='lines+markers',
                            name=sector,
                            line=dict(width=2),
                            marker=dict(size=8)
                        ))
                
                fig.update_layout(
                    title='ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œ',
                    xaxis_title='ì—°ë„',
                    yaxis_title='í‰ê·  WACC (%)',
                    hovermode='x unified',
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # íˆíŠ¸ë§µ ìƒì„±
                st.markdown("### ğŸ”¥ ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íˆíŠ¸ë§µ")
                
                fig_heatmap = go.Figure(data=go.Heatmap(
                    z=pivot_avg.values,
                    x=pivot_avg.columns,
                    y=pivot_avg.index,
                    colorscale='RdYlGn_r',  # ë¹¨ê°•-ë…¸ë‘-ì´ˆë¡ (ì—­ìˆœ, ë†’ì€ ê°’ì´ ë¹¨ê°•)
                    text=pivot_avg.values.round(2),
                    texttemplate="%{text}%",
                    textfont={"size": 10},
                    hoverongaps=False,
                    colorbar=dict(title="WACC (%)")
                ))
                
                fig_heatmap.update_layout(
                    title='ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íˆíŠ¸ë§µ',
                    xaxis_title='ì—°ë„',
                    yaxis_title='ì‚°ì—…',
                    height=400
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)
                
                # ìƒì„¸ ë°ì´í„° í‘œì‹œ
                st.markdown("### ğŸ“‹ ìƒì„¸ ë°ì´í„°")
                display_trend = trend_df.copy()
                display_trend['í‰ê· _WACC'] = display_trend['í‰ê· _WACC'].apply(lambda x: f"{x:.2f}%")
                display_trend['ì¤‘ì•™ê°’_WACC'] = display_trend['ì¤‘ì•™ê°’_WACC'].apply(lambda x: f"{x:.2f}%")
                display_trend = display_trend.sort_values(['ì‚°ì—…', 'ì—°ë„'])
                st.dataframe(display_trend, hide_index=True, use_container_width=True)
                
                # í†µê³„ ìš”ì•½
                st.markdown("### ğŸ“Š í†µê³„ ìš”ì•½")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ë¶„ì„ ì—°ë„ ìˆ˜", len(years))
                with col2:
                    st.metric("ë¶„ì„ ì‚°ì—… ìˆ˜", len(trend_df['ì‚°ì—…'].unique()))
                with col3:
                    st.metric("ì´ ë°ì´í„° í¬ì¸íŠ¸", len(trend_df))
                with col4:
                    avg_wacc = trend_df['í‰ê· _WACC'].mean()
                    st.metric("ì „ì²´ í‰ê·  WACC", f"{avg_wacc:.2f}%")
                
                return True
            else:
                st.warning("íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return True
        
        return False
        
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ ê³µì‹œ DB",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì–¸ì–´ ë²ˆì—­ ë”•ì…”ë„ˆë¦¬
TRANSLATIONS = {
    'ko': {
        'title': 'ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ ê³µì‹œ DB',
        'sidebar_title': 'ğŸ“‹ ì™¸í‰ë³´ê³ ì„œ ë¶„ì„ ì‹œìŠ¤í…œ',
        'sidebar_desc': 'ì™¸í‰ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'chat_tab': 'ğŸ’¬ ì±—ë´‡',
        'search_tab': 'ğŸ” ë°ì´í„° ê²€ìƒ‰',
        'chat_header': 'ğŸ’¬ ì˜ˆìƒ Q&A',
        'search_header': 'ğŸ” ë°ì´í„° ê²€ìƒ‰',
        'search_type': 'ê²€ìƒ‰ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:',
        'company_name': 'ê¸°ì—…ëª…',
        'industry': 'ì‚°ì—…ë¶„ë¥˜',
        'business': 'ì£¼ìš”ì‚¬ì—…',
        'issue_date': 'ë°œí–‰ì¼ì',
        'search_button': 'ê²€ìƒ‰',
        'enter_company': 'ê¸°ì—…ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:',
        'enter_industry': 'ì‚°ì—…ë¶„ë¥˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”:',
        'enter_business': 'ì£¼ìš”ì‚¬ì—…ì„ ì…ë ¥í•˜ì„¸ìš”:',
        'select_date': 'ë°œí–‰ì¼ì ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”:',
        'example_questions': 'ì˜ˆì‹œ ì§ˆë¬¸:',
        'wacc_analysis': '**WACC ë¶„ì„**',
        'similar_companies': '**ìœ ì‚¬ê¸°ì—… ë¶„ì„**',
        'period_analysis': '**ê¸°ê°„ë³„ ë¶„ì„**',
        'noa_analysis': '**ë¹„ì˜ì—…ìì‚° ë¶„ì„**',
        'qc_analysis': '**í’ˆì§ˆê´€ë¦¬(QC)**',
        'industry_finance': '**ì—°ë„ë³„ ê¸ˆìœµì—… ë¶„ì„**',
        'industry_consumer': '**ì—°ë„ë³„ ì†Œë¹„ì¬ ë¶„ì„**',
        'industry_healthcare': '**ì—°ë„ë³„ í—¬ìŠ¤ì¼€ì–´ ë¶„ì„**',
        'industry_it': '**ì—°ë„ë³„ IT ë¶„ì„**',
        'industry_manufacturing': '**ì—°ë„ë³„ ì œì¡°ì—… ë¶„ì„**',
        'industry_bio': '**ì—°ë„ë³„ ë°”ì´ì˜¤ ë¶„ì„**',
        'transaction_rel': '**ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„**',
        'other_analysis': '**ê¸°íƒ€ ë¶„ì„**',
        'yearly_stats': '**ì—°ë„ë³„ ì£¼ìš”í†µê³„**',
        'wacc_trend': '**WACC íŠ¸ë Œë“œ ë¶„ì„**',
        # ë²„íŠ¼ í…ìŠ¤íŠ¸
        'btn_virtual_asset': 'ê°€ìƒìì‚° ì‚¬ì—… ìœ ì‚¬ê¸°ì—…',
        'btn_music': 'ìŒì› ì‚¬ì—… ìœ ì‚¬ê¸°ì—…',
        'btn_ai': 'AI ì—…ê³„ ìœ ì‚¬ê¸°ì—…',
        'btn_bio': 'ë°”ì´ì˜¤ ì—…ê³„ ìœ ì‚¬ê¸°ì—…',
        'btn_game': 'ê²Œì„ ì—…ê³„ ìœ ì‚¬ê¸°ì—…',
        'btn_cloud': 'í´ë¼ìš°ë“œ ìœ ì‚¬ê¸°ì—…',
        'btn_security': 'ì •ë³´ë³´ì•ˆ ì—…ê³„ ìœ ì‚¬ê¸°ì—…',
        'btn_finance_evsales': 'ê¸ˆìœµì—… ê¸°ì—…ë“¤ì˜ EV/Sales',
        'btn_blockchain': 'ë¸”ë¡ì²´ì¸ ìœ ì‚¬ê¸°ì—…',
        'btn_industry_wacc': 'ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’',
        'btn_valuator_wacc': 'í‰ê°€ë²•ì¸ë³„ WACC ë¹„êµ',
        'btn_g_wacc': 'g â‰¥ WACC ìœ„ë°˜',
        'btn_perpetual_cf': 'ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨',
        'btn_wacc_top10': 'WACC Top 10',
        'btn_high_noa': 'ë¹„ì˜ì—…ìì‚° ë¹„ì¤‘ ë†’ì€ ê¸°ì—…',
        'btn_sector_noa': 'ì—…ì¢…ë³„ ë¹„ì˜ì—…ìì‚°êµ¬ì„±',
        'btn_de_missing': 'D/E ë¯¸ê¸°ì¬ ì˜í–¥',
        'btn_recent_valuators': 'ìµœê·¼ 12ê°œì›” í‰ê°€ë²•ì¸',
        'btn_transaction_matrix': 'ì—…ì¢… ê°„ ê±°ë˜ ë§¤íŠ¸ë¦­ìŠ¤',
        'btn_investment_mapping': 'íˆ¬ì ë§µí•‘ ë¶„ì„',
        'btn_multiple_median': 'ì‚°ì—…ë³„ ë©€í‹°í”Œ ì¤‘ì•™ê°’',
        'btn_wacc_trend': 'ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œ',
        # ì„¹ì…˜ ì œëª©
        'section_similar_q': '**ìœ ì‚¬ê¸°ì—… ì§ˆë¬¸**',
        'section_industry_similar': '**ì—…ì¢…ë³„ ìœ ì‚¬ê¸°ì—…**',
        'section_financial_ratio': '**ì¬ë¬´ë¹„ìœ¨ ì§ˆë¬¸**',
        'section_valuation': '**ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„**',
        'section_cashflow': '**í˜„ê¸ˆíë¦„ ë¶„ì„**',
        'section_noa': '**ë¹„ì˜ì—…ìì‚° ë¶„ì„**',
        # ì§ˆë¬¸ í…ìŠ¤íŠ¸
        'q_virtual_asset': 'ê°€ìƒìì‚° ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_music': 'ìŒì› ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_ai': 'AI ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_bio': 'ë°”ì´ì˜¤ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_game': 'ê²Œì„ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_cloud': 'í´ë¼ìš°ë“œ ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_security': 'ì •ë³´ë³´ì•ˆ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_finance_evsales': '2022ë…„ ì´í›„ ë°œí–‰ëœ ê¸ˆìœµì—… ê¸°ì—…ë“¤ì˜ EV/Sales ê°’ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?',
        'q_blockchain': 'ë¸”ë¡ì²´ì¸ ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'q_industry_wacc': 'ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?',
        'q_valuator_wacc': 'í‰ê°€ë²•ì¸ë³„ WACC ì¤‘ì•™ê°’ì„ ë¹„êµí•´ì£¼ì„¸ìš”',
        'q_g_wacc': 'gê°€ WACCë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì€ ìœ„ë°˜ ì‚¬ë¡€ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_perpetual_cf': 'ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ê¸°ì—…ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_wacc_top10': 'WACCê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 10ê°œ ê¸°ì—…ì€ ì–´ë””ì¸ê°€ìš”?',
        'q_high_noa': 'ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚°ì´ ë§ì€ ê¸°ì—…ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_sector_noa': 'ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±ë‚´ì—­ ë¹ˆë„ë¥¼ TOP5 ìˆœì„œë¡œ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_de_missing': 'D/E ë¯¸ê¸°ì¬ê°€ WACCì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”',
        'q_recent_valuators': 'ìµœê·¼ 12ê°œì›” ë™ì•ˆ í‰ê°€ë²•ì¸ë³„ í™œë™ëŸ‰ TOP5ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_transaction_matrix': 'ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_investment_mapping': 'ê³µì‹œë°œí–‰ê¸°ì—…ì˜ íˆ¬ì ë§µí•‘ì„ ë³´ì—¬ì£¼ì„¸ìš”',
        'q_multiple_median': 'ì‚°ì—…ë³„ EV/EBITDA ì¤‘ì•™ê°’ì„ ë¹„êµí•´ì£¼ì„¸ìš”',
        'q_wacc_trend': 'ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
        # ì…ë ¥ í•„ë“œ
        'input_question': 'ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:',
        'input_placeholder': 'ì˜ˆ: ê°€ìƒìì‚° ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
        'btn_ask': 'ì§ˆë¬¸í•˜ê¸°',
        # ì‚¬ì´ë“œë°”
        'sidebar_usage': 'ğŸ“š ì‚¬ìš©ë²•',
        'sidebar_usage_desc': '**ê°„í¸í•œ Q&A ë¶„ì„:**',
        'sidebar_usage_point1': '- ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸ ì…ë ¥',
        'sidebar_usage_point2': '- ìœ ì‚¬ê¸°ì—…, ì¬ë¬´ë¹„ìœ¨, ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ ë“± ë‹¤ì–‘í•œ ì •ë³´ ì œê³µ',
        'sidebar_usage_point3': '- API í‚¤ ì—†ì´ë„ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥',
        'sidebar_examples': 'ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸',
        'sidebar_similar_title': '**ìœ ì‚¬ê¸°ì—… ì§ˆë¬¸:**',
        'sidebar_similar_ex1': '- "ê°€ìƒìì‚° ì‚¬ì—… ìœ ì‚¬ê¸°ì—…"',
        'sidebar_similar_ex2': '- "ìŒì› ì‚¬ì—… ìœ ì‚¬ê¸°ì—…"',
        'sidebar_similar_ex3': '- "ê²Œì„ ì—…ê³„ ìœ ì‚¬ê¸°ì—…"',
        'sidebar_financial_title': '**ì¬ë¬´ë¹„ìœ¨ ì§ˆë¬¸:**',
        'sidebar_financial_ex1': '- "ê¸ˆìœµì—… ê¸°ì—…ë“¤ì˜ EV/Sales"',
        'sidebar_financial_ex2': '- "ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’"',
        'sidebar_financial_ex3': '- "í‰ê°€ë²•ì¸ë³„ WACC ë¹„êµ"',
        'sidebar_valuation_title': '**ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„:**',
        'sidebar_valuation_ex1': '- "gê°€ WACCë³´ë‹¤ í° ìœ„ë°˜ ì‚¬ë¡€"',
        'sidebar_valuation_ex2': '- "D/E ë¯¸ê¸°ì¬ ì˜í–¥ ë¶„ì„"',
        'sidebar_valuation_ex3': '- "WACC Top 10"',
        'sidebar_new_title': '**ìƒˆë¡œìš´ ë¶„ì„:**',
        'sidebar_new_ex1': '- "ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ê¸°ì—…"',
        'sidebar_new_ex2': '- "ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±ë‚´ì—­ TOP5"',
        'sidebar_new_ex3': '- "2023ë…„ í—¬ìŠ¤ì¼€ì–´ WACC"',
        'sidebar_new_ex4': '- "2022ë…„ ITì—… WACC"',
        'sidebar_new_ex5': '- "2023ë…„ ë°”ì´ì˜¤ WACC"',
        'sidebar_new_ex6': '- "ì—°ë„ë³„ ê¸ˆìœµì—…/ì†Œë¹„ì¬/í—¬ìŠ¤ì¼€ì–´ WACC"',
    },
    'en': {
        'title': 'Key Disclosure Reports DB',
        'sidebar_title': 'ğŸ“‹ Valuation Report Analysis System',
        'sidebar_desc': 'Analyze and search valuation report data.',
        'chat_tab': 'ğŸ’¬ Chatbot',
        'search_tab': 'ğŸ” Data Search',
        'chat_header': 'ğŸ’¬ Expected Q&A',
        'search_header': 'ğŸ” Data Search',
        'search_type': 'Select search type:',
        'company_name': 'Company Name',
        'industry': 'Industry',
        'business': 'Main Business',
        'issue_date': 'Issue Date',
        'search_button': 'Search',
        'enter_company': 'Enter company name:',
        'enter_industry': 'Enter industry:',
        'enter_business': 'Enter main business:',
        'select_date': 'Select date range:',
        'example_questions': 'Example Questions:',
        'wacc_analysis': '**WACC Analysis**',
        'similar_companies': '**Similar Companies Analysis**',
        'period_analysis': '**Period Analysis**',
        'noa_analysis': '**Non-Operating Assets Analysis**',
        'qc_analysis': '**Quality Control (QC)**',
        'industry_finance': '**Annual Finance Industry Analysis**',
        'industry_consumer': '**Annual Consumer Industry Analysis**',
        'industry_healthcare': '**Annual Healthcare Industry Analysis**',
        'industry_it': '**Annual IT Industry Analysis**',
        'industry_manufacturing': '**Annual Manufacturing Industry Analysis**',
        'industry_bio': '**Annual Bio Industry Analysis**',
        'transaction_rel': '**Inter-Industry Transaction Relations**',
        'other_analysis': '**Other Analysis**',
        'yearly_stats': '**Annual Key Statistics**',
        'wacc_trend': '**WACC Trend Analysis**',
        # ë²„íŠ¼ í…ìŠ¤íŠ¸
        'btn_virtual_asset': 'Virtual Asset Business Similar Companies',
        'btn_music': 'Music Business Similar Companies',
        'btn_ai': 'AI Industry Similar Companies',
        'btn_bio': 'Bio Industry Similar Companies',
        'btn_game': 'Game Industry Similar Companies',
        'btn_cloud': 'Cloud Similar Companies',
        'btn_security': 'Information Security Industry Similar Companies',
        'btn_finance_evsales': 'Finance Industry EV/Sales',
        'btn_blockchain': 'Blockchain Similar Companies',
        'btn_industry_wacc': 'Industry WACC Median',
        'btn_valuator_wacc': 'Compare WACC by Valuation Firm',
        'btn_g_wacc': 'g â‰¥ WACC Violation',
        'btn_perpetual_cf': 'Perpetual Cash Flow Ratio',
        'btn_wacc_top10': 'WACC Top 10',
        'btn_high_noa': 'Companies with High Non-Operating Assets',
        'btn_sector_noa': 'Non-Operating Assets by Industry',
        'btn_de_missing': 'D/E Non-Disclosure Impact',
        'btn_recent_valuators': 'Valuation Firms (Last 12 Months)',
        'btn_transaction_matrix': 'Inter-Industry Transaction Matrix',
        'btn_investment_mapping': 'Investment Mapping Analysis',
        'btn_multiple_median': 'Industry Multiples Median',
        'btn_wacc_trend': 'Annual Industry WACC Trend',
        # ì„¹ì…˜ ì œëª©
        'section_similar_q': '**Similar Company Questions**',
        'section_industry_similar': '**Industry-Specific Similar Companies**',
        'section_financial_ratio': '**Financial Ratio Questions**',
        'section_valuation': '**Valuation Analysis**',
        'section_cashflow': '**Cash Flow Analysis**',
        'section_noa': '**Non-Operating Assets Analysis**',
        # ì§ˆë¬¸ í…ìŠ¤íŠ¸
        'q_virtual_asset': 'What are the similar companies selected by companies in the virtual asset business?',
        'q_music': 'What are the similar companies selected by companies in the music business?',
        'q_ai': 'What are the similar companies selected by companies in the AI industry?',
        'q_bio': 'What are the similar companies selected by companies in the bio industry?',
        'q_game': 'What are the similar companies selected by companies in the game industry?',
        'q_cloud': 'What are the similar companies selected by companies in the cloud business?',
        'q_security': 'What are the similar companies selected by companies in the information security industry?',
        'q_finance_evsales': 'What are the EV/Sales values of finance industry companies issued after 2022?',
        'q_blockchain': 'What are the similar companies selected by companies in the blockchain business?',
        'q_industry_wacc': 'What is the industry WACC median?',
        'q_valuator_wacc': 'Please compare the WACC median by valuation firm',
        'q_g_wacc': 'Please show cases where g is greater than or equal to WACC',
        'q_perpetual_cf': 'Please show companies with perpetual cash flow ratio over 50%',
        'q_wacc_top10': 'What are the top 10 companies with the highest WACC?',
        'q_high_noa': 'Please show companies with high non-operating assets relative to enterprise value',
        'q_sector_noa': 'Please show the top 5 non-operating asset composition by industry in order',
        'q_de_missing': 'Please analyze the impact of D/E non-disclosure on WACC',
        'q_recent_valuators': 'Please show the top 5 valuation firms by activity in the last 12 months',
        'q_transaction_matrix': 'Please show inter-industry transaction relationships',
        'q_investment_mapping': 'Please show investment mapping of public offering companies',
        'q_multiple_median': 'Please compare industry EV/EBITDA medians',
        'q_wacc_trend': 'Please show annual industry WACC trends',
        # ì…ë ¥ í•„ë“œ
        'input_question': 'Enter your question:',
        'input_placeholder': 'Example: What are the similar companies selected by companies in the virtual asset business?',
        'btn_ask': 'Ask',
        # ì‚¬ì´ë“œë°”
        'sidebar_usage': 'ğŸ“š Usage',
        'sidebar_usage_desc': '**Easy Q&A Analysis:**',
        'sidebar_usage_point1': '- Click example question buttons or directly enter questions',
        'sidebar_usage_point2': '- Provides various information such as similar companies, financial ratios, and valuation analysis',
        'sidebar_usage_point3': '- All functions available without an API key',
        'sidebar_examples': 'ğŸ’¡ Example Questions',
        'sidebar_similar_title': '**Similar Company Questions:**',
        'sidebar_similar_ex1': '- "Virtual asset business similar companies"',
        'sidebar_similar_ex2': '- "Music business similar companies"',
        'sidebar_similar_ex3': '- "Game industry similar companies"',
        'sidebar_financial_title': '**Financial Ratio Questions:**',
        'sidebar_financial_ex1': '- "Finance industry EV/Sales"',
        'sidebar_financial_ex2': '- "Industry WACC median"',
        'sidebar_financial_ex3': '- "Compare WACC by valuation firm"',
        'sidebar_valuation_title': '**Valuation Analysis:**',
        'sidebar_valuation_ex1': '- "Cases where g is greater than WACC"',
        'sidebar_valuation_ex2': '- "D/E non-disclosure impact analysis"',
        'sidebar_valuation_ex3': '- "WACC Top 10"',
        'sidebar_new_title': '**New Analysis:**',
        'sidebar_new_ex1': '- "Companies with perpetual cash flow ratio over 50%"',
        'sidebar_new_ex2': '- "Top 5 non-operating asset composition by industry"',
        'sidebar_new_ex3': '- "2023 Healthcare WACC"',
        'sidebar_new_ex4': '- "2022 IT Industry WACC"',
        'sidebar_new_ex5': '- "2023 Bio WACC"',
        'sidebar_new_ex6': '- "Annual Finance/Consumer/Healthcare WACC"',
    }
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'gpt_chatbot' not in st.session_state:
    st.session_state.gpt_chatbot = None
if 'language' not in st.session_state:
    st.session_state.language = 'ko'  # ê¸°ë³¸ ì–¸ì–´ëŠ” í•œêµ­ì–´

# ì˜ì–´ ì§ˆë¬¸ì„ í•œê¸€ ì§ˆë¬¸ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
EN_TO_KO_QUESTIONS = {
    # ìœ ì‚¬ê¸°ì—… ì§ˆë¬¸
    'What are the similar companies selected by companies in the virtual asset business?': 'ê°€ìƒìì‚° ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the music business?': 'ìŒì› ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the AI industry?': 'AI ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the bio industry?': 'ë°”ì´ì˜¤ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the game industry?': 'ê²Œì„ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the cloud business?': 'í´ë¼ìš°ë“œ ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the information security industry?': 'ì •ë³´ë³´ì•ˆ ì—…ê³„ ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    'What are the similar companies selected by companies in the blockchain business?': 'ë¸”ë¡ì²´ì¸ ì‚¬ì—…ì„ í•˜ëŠ” ê¸°ì—…ë“¤ì´ ì„ ì •í•œ ìœ ì‚¬ê¸°ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?',
    # ì¬ë¬´ë¹„ìœ¨ ì§ˆë¬¸
    'What are the EV/Sales values of finance industry companies issued after 2022?': '2022ë…„ ì´í›„ ë°œí–‰ëœ ê¸ˆìœµì—… ê¸°ì—…ë“¤ì˜ EV/Sales ê°’ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?',
    # ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„
    'What is the industry WACC median?': 'ì‚°ì—…ë³„ WACC ì¤‘ì•™ê°’ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?',
    'Please compare the WACC median by valuation firm': 'í‰ê°€ë²•ì¸ë³„ WACC ì¤‘ì•™ê°’ì„ ë¹„êµí•´ì£¼ì„¸ìš”',
    'Please show cases where g is greater than or equal to WACC': 'gê°€ WACCë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì€ ìœ„ë°˜ ì‚¬ë¡€ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
    # í˜„ê¸ˆíë¦„ ë¶„ì„
    'Please show companies with perpetual cash flow ratio over 50%': 'ì˜êµ¬í˜„ê¸ˆíë¦„ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ê¸°ì—…ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
    'What are the top 10 companies with the highest WACC?': 'WACCê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 10ê°œ ê¸°ì—…ì€ ì–´ë””ì¸ê°€ìš”?',
    # ë¹„ì˜ì—…ìì‚° ë¶„ì„
    'Please show companies with high non-operating assets relative to enterprise value': 'ê¸°ì—…ê°€ì¹˜ ëŒ€ë¹„ ë¹„ì˜ì—…ìì‚°ì´ ë§ì€ ê¸°ì—…ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”',
    'Please show the top 5 non-operating asset composition by industry in order': 'ì—…ì¢…ë³„ ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±ë‚´ì—­ ë¹ˆë„ë¥¼ TOP5 ìˆœì„œë¡œ ë³´ì—¬ì£¼ì„¸ìš”',
    # í’ˆì§ˆê´€ë¦¬
    'Please analyze the impact of D/E non-disclosure on WACC': 'D/E ë¯¸ê¸°ì¬ê°€ WACCì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”',
    'Please show the top 5 valuation firms by activity in the last 12 months': 'ìµœê·¼ 12ê°œì›” ë™ì•ˆ í‰ê°€ë²•ì¸ë³„ í™œë™ëŸ‰ TOP5ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    # ê±°ë˜ ê´€ê³„
    'Please show inter-industry transaction relationships': 'ì—…ì¢… ê°„ ê±°ë˜ ê´€ê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    'Please show investment mapping of public offering companies': 'ê³µì‹œë°œí–‰ê¸°ì—…ì˜ íˆ¬ì ë§µí•‘ì„ ë³´ì—¬ì£¼ì„¸ìš”',
    # ê¸°íƒ€ ë¶„ì„
    'Please compare industry EV/EBITDA medians': 'ì‚°ì—…ë³„ EV/EBITDA ì¤‘ì•™ê°’ì„ ë¹„êµí•´ì£¼ì„¸ìš”',
    'Please show annual industry WACC trends': 'ì—°ë„ë³„ ì‚°ì—…ë³„ WACC íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    # ì—°ë„ë³„ WACC ì§ˆë¬¸
    'What is the average WACC of the finance industry in 2022?': '2022ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the finance industry in 2023?': '2023ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the finance industry in 2024?': '2024ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the finance industry in 2025?': '2025ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the consumer industry in 2022?': '2022ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the consumer industry in 2023?': '2023ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the consumer industry in 2024?': '2024ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the consumer industry in 2025?': '2025ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the healthcare industry in 2022?': '2022ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the healthcare industry in 2023?': '2023ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the healthcare industry in 2024?': '2024ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the healthcare industry in 2025?': '2025ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the IT industry in 2022?': '2022ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the IT industry in 2023?': '2023ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the IT industry in 2024?': '2024ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the IT industry in 2025?': '2025ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the manufacturing industry in 2022?': '2022ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the manufacturing industry in 2023?': '2023ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the manufacturing industry in 2024?': '2024ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the manufacturing industry in 2025?': '2025ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the bio industry in 2022?': '2022ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the bio industry in 2023?': '2023ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the bio industry in 2024?': '2024ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of the bio industry in 2025?': '2025ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of all industries in 2024?': '2024ë…„ ì „ì²´ ì—…ì¢…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    'What is the average WACC of all industries in 2025?': '2025ë…„ ì „ì²´ ì—…ì¢…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?',
    # ì—°ë„ë³„ ì£¼ìš”í†µê³„
    'Please show 2022 key statistics': '2022ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    'Please show 2023 key statistics': '2023ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    'Please show 2024 key statistics': '2024ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
    'Please show 2025 key statistics': '2025ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”',
}

def translate_question_to_korean(question):
    """ì˜ì–´ ì§ˆë¬¸ì„ í•œê¸€ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜"""
    if question in EN_TO_KO_QUESTIONS:
        return EN_TO_KO_QUESTIONS[question]
    return question  # ë§¤í•‘ì´ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    try:
        conn = sqlite3.connect(config.DATABASE_PATH)
        return conn
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

# ë°ì´í„° ê²€ìƒ‰ í•¨ìˆ˜ë“¤
def search_by_sector(sector):
    """íŠ¹ì • ì„¹í„°/ì‚°ì—…ì˜ ê¸°ì—…ë“¤ ê²€ìƒ‰"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT DISTINCT 
        ê³µì‹œë³´ê³ ì„œëª…,
        ë°œí–‰ì¼ì,
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
        ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
        í‰ê°€ëŒ€ìƒê¸°ì—…ëª…,
        í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…,
        ìœ ì‚¬ê¸°ì—…,
        WACC,
        Link
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ LIKE ? OR í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—… LIKE ?
    ORDER BY ë°œí–‰ì¼ì DESC
    """
    
    try:
        df = pd.read_sql_query(query, conn, params=[f'%{sector}%', f'%{sector}%'])
        conn.close()
        return df
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        conn.close()
        return pd.DataFrame()

def search_by_company_name(company_name):
    """ê¸°ì—…ëª…ìœ¼ë¡œ ê²€ìƒ‰"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT DISTINCT 
        ê³µì‹œë³´ê³ ì„œëª…,
        ë°œí–‰ì¼ì,
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
        ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
        í‰ê°€ëŒ€ìƒê¸°ì—…ëª…,
        í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…,
        ìœ ì‚¬ê¸°ì—…,
        WACC,
        Link
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE ê³µì‹œë°œí–‰_ê¸°ì—…ëª… LIKE ? OR í‰ê°€ëŒ€ìƒê¸°ì—…ëª… LIKE ?
    ORDER BY ë°œí–‰ì¼ì DESC
    """
    
    try:
        df = pd.read_sql_query(query, conn, params=[f'%{company_name}%', f'%{company_name}%'])
        conn.close()
        return df
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        conn.close()
        return pd.DataFrame()

def search_by_business(business):
    """ì£¼ìš”ì‚¬ì—…ìœ¼ë¡œ ê²€ìƒ‰"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT DISTINCT 
        ê³µì‹œë³´ê³ ì„œëª…,
        ë°œí–‰ì¼ì,
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
        ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
        í‰ê°€ëŒ€ìƒê¸°ì—…ëª…,
        í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…,
        ìœ ì‚¬ê¸°ì—…,
        WACC,
        Link
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—… LIKE ?
    ORDER BY ë°œí–‰ì¼ì DESC
    """
    
    try:
        df = pd.read_sql_query(query, conn, params=[f'%{business}%'])
        conn.close()
        return df
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        conn.close()
        return pd.DataFrame()

def search_by_date_range(start_date_str, end_date_str=None):
    """ë°œí–‰ì¼ì ê¸°ê°„ ë²”ìœ„ë¡œ ê²€ìƒ‰"""
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    query = """
    SELECT DISTINCT 
        ê³µì‹œë³´ê³ ì„œëª…,
        ë°œí–‰ì¼ì,
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
        ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
        í‰ê°€ëŒ€ìƒê¸°ì—…ëª…,
        í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…,
        ìœ ì‚¬ê¸°ì—…,
        WACC,
        Link
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE ë°œí–‰ì¼ì >= ?
    """
    
    params = [start_date_str]
    
    if end_date_str:
        query += " AND ë°œí–‰ì¼ì <= ?"
        params.append(end_date_str)
    else:
        # ì¢…ë£Œì¼ì´ ì—†ìœ¼ë©´ ì‹œì‘ì¼ë§Œ ì‚¬ìš© (ë‹¨ì¼ ë‚ ì§œ ê²€ìƒ‰)
        query += " AND ë°œí–‰ì¼ì <= ?"
        params.append(start_date_str)
    
    query += " ORDER BY ë°œí–‰ì¼ì DESC"
    
    try:
        df = pd.read_sql_query(query, conn, params=params)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        conn.close()
        return pd.DataFrame()

def search_similar_companies(business_keyword):
    """
    íŠ¹ì • ì‚¬ì—… í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ìœ ì‚¬ê¸°ì—… ì •ë³´ë¥¼ ê²€ìƒ‰
    """
    try:
        conn = sqlite3.connect('ì™¸í‰ë³´ê³ ì„œ.db')
        
        # ìŒì›, ê°€ìƒìì‚° ë“± íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•œ ë” ì •í™•í•œ ê²€ìƒ‰
        query = """
        SELECT DISTINCT
            ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
            ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
            í‰ê°€ëŒ€ìƒê¸°ì—…ëª…,
            í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
            í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…,
            ê³µì‹œë³´ê³ ì„œëª…,
            ë°œí–‰ì¼ì,
            ìœ ì‚¬ê¸°ì—…,
            Link
        FROM ì™¸í‰ë³´ê³ ì„œ
        WHERE (
            í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—… LIKE ? OR 
            í‰ê°€ëŒ€ìƒê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ LIKE ? OR
            ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ LIKE ?
        )
        AND ìœ ì‚¬ê¸°ì—… IS NOT NULL AND ìœ ì‚¬ê¸°ì—… != ''
        ORDER BY ë°œí–‰ì¼ì DESC
        """
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ì„ ìœ„í•œ íŒ¨í„´ ìƒì„±
        keyword_pattern = f"%{business_keyword}%"
        
        df = pd.read_sql_query(query, conn, params=[keyword_pattern, keyword_pattern, keyword_pattern])
        conn.close()
        
        return df
        
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def search_financial_ratios(sector, start_date=None, end_date=None):
    """íŠ¹ì • ì„¹í„°ì™€ ê¸°ê°„ì˜ ì¬ë¬´ë¹„ìœ¨ ê²€ìƒ‰"""
    conn = get_db_connection()
    if conn is None:
        return None
    
    # ê¸°ë³¸ ì¿¼ë¦¬ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
    query = """
    SELECT 
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª…,
        ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜,
        ë°œí–‰ì¼ì,
        "EV/Sales",
        PSR,
        Ke,
        Kd,
        WACC,
        "D/E"
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE (ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ LIKE ? OR í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—… LIKE ?)
    """
    
    params = [f'%{sector}%', f'%{sector}%']
    
    # ë‚ ì§œ í•„í„° ì¶”ê°€
    if start_date:
        query += " AND ë°œí–‰ì¼ì >= ?"
        params.append(start_date)
    if end_date:
        query += " AND ë°œí–‰ì¼ì <= ?"
        params.append(end_date)
    
    query += " ORDER BY ë°œí–‰ì¼ì DESC"
    
    try:
        df = pd.read_sql_query(query, conn, params=params)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        conn.close()
        return None

def get_available_sectors():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¹í„° ëª©ë¡ ì¡°íšŒ"""
    conn = get_db_connection()
    if conn is None:
        return []
    
    query = """
    SELECT DISTINCT ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ 
    FROM ì™¸í‰ë³´ê³ ì„œ 
    WHERE ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ IS NOT NULL 
    AND ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜ != ''
    ORDER BY ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜
    """
    
    try:
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df['ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜'].tolist()
    except Exception as e:
        st.error(f"ì„¹í„° ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        conn.close()
        return []


def add_to_chat_history(question, answer, data=None):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ëŒ€í™” ì¶”ê°€"""
    st.session_state.chat_history.append({
        'question': question,
        'answer': answer,
        'data': data,
        'timestamp': datetime.now()
    })

def display_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
    if not st.session_state.chat_history:
        return
    
    st.subheader("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    
    for i, chat in enumerate(reversed(st.session_state.chat_history)):
        with st.expander(f"ì§ˆë¬¸ {len(st.session_state.chat_history) - i}: {chat['question'][:50]}...", expanded=False):
            st.markdown(f"**ì§ˆë¬¸:** {chat['question']}")
            st.markdown(f"**ë‹µë³€:** {chat['answer']}")
            
            if chat['data'] is not None and not chat['data'].empty:
                st.markdown("**ê´€ë ¨ ë°ì´í„°:**")
                st.dataframe(chat['data'])
            
            st.markdown(f"*{chat['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}*")

def generate_structured_sentences(data):
    """ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë¬¸ì¥ì„ ìë™ ìƒì„±"""
    if data.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    sentences = []
    
    for idx, row in data.iterrows():
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        ë°œí–‰ì¼ì = row.get('ë°œí–‰ì¼ì', 'N/A')
        ê³µì‹œë°œí–‰_ê¸°ì—…ëª… = row.get('ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'N/A')
        í‰ê°€ëŒ€ìƒê¸°ì—…ëª… = row.get('í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'N/A')
        ê³µì‹œë³´ê³ ì„œëª… = row.get('ê³µì‹œë³´ê³ ì„œëª…', 'N/A')
        ìœ ì‚¬ê¸°ì—… = row.get('ìœ ì‚¬ê¸°ì—…', 'N/A')
        Link = row.get('Link', '')
        
        # ê³µì‹œë³´ê³ ì„œëª…ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if pd.isna(ê³µì‹œë³´ê³ ì„œëª…) or ê³µì‹œë³´ê³ ì„œëª… == '':
            ê³µì‹œë³´ê³ ì„œëª… = "ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ"
        
        # ìœ ì‚¬ê¸°ì—… ì •ë³´ ì •ë¦¬
        if pd.notna(ìœ ì‚¬ê¸°ì—…) and ìœ ì‚¬ê¸°ì—… != '':
            # ì‰¼í‘œë‚˜ ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ êµ¬ë¶„ëœ ìœ ì‚¬ê¸°ì—…ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(ìœ ì‚¬ê¸°ì—…, str):
                similar_companies = [company.strip() for company in ìœ ì‚¬ê¸°ì—….replace(';', ',').split(',') if company.strip()]
            else:
                similar_companies = [str(ìœ ì‚¬ê¸°ì—…)]
            
            # ìœ ì‚¬ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰¼í‘œë¡œ ì—°ê²°
            similar_companies_str = ', '.join(similar_companies)
            
            # ë¬¸ì¥ ìƒì„±
            sentence = f"{ë°œí–‰ì¼ì}\n{ê³µì‹œë°œí–‰_ê¸°ì—…ëª…}ì€ ã€Œ{ê³µì‹œë³´ê³ ì„œëª…}ã€ì—ì„œ {í‰ê°€ëŒ€ìƒê¸°ì—…ëª…} ê´€ë ¨ í‰ê°€ ì‹œ ìœ ì‚¬ê¸°ì—…ìœ¼ë¡œ {similar_companies_str}ì„ ì„ ì •í–ˆë‹¤."
            
            # ë§í¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if pd.notna(Link) and Link != '' and str(Link).strip() != '':
                sentence += f"\n\nì›ë¬¸ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤: {Link}"
            
            sentences.append(sentence)
    
    return "\n\n".join(sentences)

# ë©”ì¸ ì•±
def main():
    # ì–¸ì–´ ì„ íƒ
    lang = st.session_state.language
    t = TRANSLATIONS[lang]
    
    # ìƒë‹¨ì— ì–¸ì–´ ì „í™˜ ë²„íŠ¼
    col_lang1, col_lang2, col_lang_space = st.columns([1, 1, 10])
    with col_lang1:
        if st.button("ğŸ‡°ğŸ‡· KR", key="lang_kr", use_container_width=True):
            st.session_state.language = 'ko'
            st.rerun()
    with col_lang2:
        if st.button("ğŸ‡ºğŸ‡¸ EN", key="lang_en", use_container_width=True):
            st.session_state.language = 'en'
            st.rerun()
    
    st.title(f"ğŸ“Š {t['title']}")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header(t['sidebar_usage'])
        st.markdown(f"""
        {t['sidebar_usage_desc']}
        - {t['sidebar_usage_point1']}
        - {t['sidebar_usage_point2']}
        - {t['sidebar_usage_point3']}
        """)
        
        st.markdown("---")
        st.header(t['sidebar_examples'])
        st.markdown(f"""
        {t['sidebar_similar_title']}
        - {t['sidebar_similar_ex1']}
        - {t['sidebar_similar_ex2']}
        - {t['sidebar_similar_ex3']}
        
        {t['sidebar_financial_title']}
        - {t['sidebar_financial_ex1']}
        - {t['sidebar_financial_ex2']}
        - {t['sidebar_financial_ex3']}
        
        {t['sidebar_valuation_title']}
        - {t['sidebar_valuation_ex1']}
        - {t['sidebar_valuation_ex2']}
        - {t['sidebar_valuation_ex3']}
        
        {t['sidebar_new_title']}
        - {t['sidebar_new_ex1']}
        - {t['sidebar_new_ex2']}
        - {t['sidebar_new_ex3']}
        - {t['sidebar_new_ex4']}
        - {t['sidebar_new_ex5']}
        - {t['sidebar_new_ex6']}
        """)
    
    # ë©”ì¸ íƒ­
    tab1,  tab2 = st.tabs([t['chat_tab'],  t['search_tab']])
    
    with tab1:
        st.header(t['chat_header'])
        
        # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ë“¤
        col1, col2, col3, col4 = st.columns(4)
        
        # ì²« ë²ˆì§¸ í–‰: ìœ ì‚¬ê¸°ì—… ì§ˆë¬¸ë“¤
        with col1:
            st.markdown(t['section_similar_q'])
            if st.button(t['btn_virtual_asset'], key="virtual_asset_companies"):
                st.session_state.example_question = t['q_virtual_asset']
            if st.button(t['btn_music'], key="music_companies"):
                st.session_state.example_question = t['q_music']
            if st.button(t['btn_ai'], key="ai_companies"):
                st.session_state.example_question = t['q_ai']
        
        with col2:
            st.markdown(t['section_industry_similar'])
            if st.button(t['btn_bio'], key="bio_companies"):
                st.session_state.example_question = t['q_bio']
            if st.button(t['btn_game'], key="game_companies"):
                st.session_state.example_question = t['q_game']
            if st.button(t['btn_cloud'], key="cloud_companies"):
                st.session_state.example_question = t['q_cloud']
        
        with col3:
            st.markdown(t['section_financial_ratio'])
            if st.button(t['btn_security'], key="security_companies"):
                st.session_state.example_question = t['q_security']
            if st.button(t['btn_finance_evsales'], key="finance_evsales"):
                st.session_state.example_question = t['q_finance_evsales']
            if st.button(t['btn_blockchain'], key="blockchain_companies"):
                st.session_state.example_question = t['q_blockchain']
        
        with col4:
            st.markdown(t['section_valuation'])
            if st.button(t['btn_industry_wacc'], key="industry_wacc_median"):
                st.session_state.example_question = t['q_industry_wacc']
            if st.button(t['btn_valuator_wacc'], key="valuator_wacc_compare"):
                st.session_state.example_question = t['q_valuator_wacc']
            if st.button(t['btn_g_wacc'], key="g_wacc_violation"):
                st.session_state.example_question = t['q_g_wacc']
        
        # ë‘ ë²ˆì§¸ í–‰: ìƒˆë¡œìš´ ì§ˆë¬¸ë“¤
        st.markdown("---")
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            st.markdown(t['section_cashflow'])
            if st.button(t['btn_perpetual_cf'], key="perpetual_cashflow_ratio"):
                st.session_state.example_question = t['q_perpetual_cf']
            if st.button(t['btn_wacc_top10'], key="wacc_top10"):
                st.session_state.example_question = t['q_wacc_top10']
        
        with col6:
            st.markdown(t['section_noa'])
            if st.button(t['btn_high_noa'], key="high_noa_companies"):
                st.session_state.example_question = t['q_high_noa']
            if st.button(t['btn_sector_noa'], key="sector_noa_composition"):
                st.session_state.example_question = t['q_sector_noa']
        
        with col7:
            st.markdown(t['qc_analysis'])
            if st.button(t['btn_de_missing'], key="de_missing_impact"):
                st.session_state.example_question = t['q_de_missing']
            if st.button(t['btn_recent_valuators'], key="recent_12m_valuators"):
                st.session_state.example_question = t['q_recent_valuators']
        
        
        # ì„¸ ë²ˆì§¸ í–‰: ì¶”ê°€ ì—°ë„ë³„+ì—…ì¢…ë³„ ì¡°í•©
        st.markdown("---")
        col9, col10, col11, col12, col13 = st.columns(5)
        
        with col9:
            st.markdown(t['industry_finance'])
            year_btn_text = {2022: "2022ë…„ ê¸ˆìœµì—… WACC" if lang == 'ko' else "2022 Finance WACC",
                             2023: "2023ë…„ ê¸ˆìœµì—… WACC" if lang == 'ko' else "2023 Finance WACC",
                             2024: "2024ë…„ ê¸ˆìœµì—… WACC" if lang == 'ko' else "2024 Finance WACC",
                             2025: "2025ë…„ ê¸ˆìœµì—… WACC" if lang == 'ko' else "2025 Finance WACC"}
            year_q_text = {2022: "2022ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the finance industry in 2022?",
                           2023: "2023ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the finance industry in 2023?",
                           2024: "2024ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the finance industry in 2024?",
                           2025: "2025ë…„ ê¸ˆìœµì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the finance industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"finance_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col10:
            st.markdown(t['industry_consumer'])
            year_btn_text = {2022: "2022ë…„ ì†Œë¹„ì¬ WACC" if lang == 'ko' else "2022 Consumer WACC",
                             2023: "2023ë…„ ì†Œë¹„ì¬ WACC" if lang == 'ko' else "2023 Consumer WACC",
                             2024: "2024ë…„ ì†Œë¹„ì¬ WACC" if lang == 'ko' else "2024 Consumer WACC",
                             2025: "2025ë…„ ì†Œë¹„ì¬ WACC" if lang == 'ko' else "2025 Consumer WACC"}
            year_q_text = {2022: "2022ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the consumer industry in 2022?",
                           2023: "2023ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the consumer industry in 2023?",
                           2024: "2024ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the consumer industry in 2024?",
                           2025: "2025ë…„ ì†Œë¹„ì¬ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the consumer industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"consumer_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col11:
            st.markdown(t['industry_healthcare'])
            year_btn_text = {2022: "2022ë…„ í—¬ìŠ¤ì¼€ì–´ WACC" if lang == 'ko' else "2022 Healthcare WACC",
                             2023: "2023ë…„ í—¬ìŠ¤ì¼€ì–´ WACC" if lang == 'ko' else "2023 Healthcare WACC",
                             2024: "2024ë…„ í—¬ìŠ¤ì¼€ì–´ WACC" if lang == 'ko' else "2024 Healthcare WACC",
                             2025: "2025ë…„ í—¬ìŠ¤ì¼€ì–´ WACC" if lang == 'ko' else "2025 Healthcare WACC"}
            year_q_text = {2022: "2022ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the healthcare industry in 2022?",
                           2023: "2023ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the healthcare industry in 2023?",
                           2024: "2024ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the healthcare industry in 2024?",
                           2025: "2025ë…„ í—¬ìŠ¤ì¼€ì–´ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the healthcare industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"healthcare_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col12:
            st.markdown(t['industry_it'])
            year_btn_text = {2022: "2022ë…„ IT WACC" if lang == 'ko' else "2022 IT WACC",
                             2023: "2023ë…„ IT WACC" if lang == 'ko' else "2023 IT WACC",
                             2024: "2024ë…„ IT WACC" if lang == 'ko' else "2024 IT WACC",
                             2025: "2025ë…„ IT WACC" if lang == 'ko' else "2025 IT WACC"}
            year_q_text = {2022: "2022ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the IT industry in 2022?",
                           2023: "2023ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the IT industry in 2023?",
                           2024: "2024ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the IT industry in 2024?",
                           2025: "2025ë…„ ITì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the IT industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"it_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col13:
            st.markdown(t['industry_manufacturing'])
            year_btn_text = {2022: "2022ë…„ ì œì¡°ì—… WACC" if lang == 'ko' else "2022 Manufacturing WACC",
                             2023: "2023ë…„ ì œì¡°ì—… WACC" if lang == 'ko' else "2023 Manufacturing WACC",
                             2024: "2024ë…„ ì œì¡°ì—… WACC" if lang == 'ko' else "2024 Manufacturing WACC",
                             2025: "2025ë…„ ì œì¡°ì—… WACC" if lang == 'ko' else "2025 Manufacturing WACC"}
            year_q_text = {2022: "2022ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the manufacturing industry in 2022?",
                           2023: "2023ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the manufacturing industry in 2023?",
                           2024: "2024ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the manufacturing industry in 2024?",
                           2025: "2025ë…„ ì œì¡°ì—…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the manufacturing industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"manufacturing_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        # ë„¤ ë²ˆì§¸ í–‰: ì¶”ê°€ ì—…ì¢… ë° ê¸°íƒ€ ë¶„ì„
        st.markdown("---")
        col14, col15, col16, col17, col18 = st.columns(5)
        
        with col14:
            st.markdown(t['industry_bio'])
            year_btn_text = {2022: "2022ë…„ ë°”ì´ì˜¤ WACC" if lang == 'ko' else "2022 Bio WACC",
                             2023: "2023ë…„ ë°”ì´ì˜¤ WACC" if lang == 'ko' else "2023 Bio WACC",
                             2024: "2024ë…„ ë°”ì´ì˜¤ WACC" if lang == 'ko' else "2024 Bio WACC",
                             2025: "2025ë…„ ë°”ì´ì˜¤ WACC" if lang == 'ko' else "2025 Bio WACC"}
            year_q_text = {2022: "2022ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the bio industry in 2022?",
                           2023: "2023ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the bio industry in 2023?",
                           2024: "2024ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the bio industry in 2024?",
                           2025: "2025ë…„ ë°”ì´ì˜¤ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of the bio industry in 2025?"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"bio_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col15:
            st.markdown(t['transaction_rel'])
            if st.button(t['btn_transaction_matrix'], key="sector_transaction_matrix"):
                st.session_state.example_question = t['q_transaction_matrix']
            if st.button(t['btn_investment_mapping'], key="investment_mapping"):
                st.session_state.example_question = t['q_investment_mapping']
        
        with col16:
            st.markdown(t['other_analysis'])
            if st.button(t['btn_multiple_median'], key="industry_multiple_median"):
                st.session_state.example_question = t['q_multiple_median']
            year_btn_text = {2024: "2024ë…„ ì „ì²´ WACC" if lang == 'ko' else "2024 Overall WACC",
                             2025: "2025ë…„ ì „ì²´ WACC" if lang == 'ko' else "2025 Overall WACC"}
            year_q_text = {2024: "2024ë…„ ì „ì²´ ì—…ì¢…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of all industries in 2024?",
                           2025: "2025ë…„ ì „ì²´ ì—…ì¢…ì˜ í‰ê·  WACCëŠ” ì–¼ë§ˆì¸ê°€ìš”?" if lang == 'ko' else "What is the average WACC of all industries in 2025?"}
            for year in [2024, 2025]:
                if st.button(year_btn_text[year], key=f"overall_{year}_wacc"):
                    st.session_state.example_question = year_q_text[year]
        
        with col17:
            st.markdown(t['yearly_stats'])
            year_btn_text = {2022: "2022ë…„ ì£¼ìš”í†µê³„" if lang == 'ko' else "2022 Key Statistics",
                             2023: "2023ë…„ ì£¼ìš”í†µê³„" if lang == 'ko' else "2023 Key Statistics",
                             2024: "2024ë…„ ì£¼ìš”í†µê³„" if lang == 'ko' else "2024 Key Statistics",
                             2025: "2025ë…„ ì£¼ìš”í†µê³„" if lang == 'ko' else "2025 Key Statistics"}
            year_q_text = {2022: "2022ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”" if lang == 'ko' else "Please show 2022 key statistics",
                           2023: "2023ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”" if lang == 'ko' else "Please show 2023 key statistics",
                           2024: "2024ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”" if lang == 'ko' else "Please show 2024 key statistics",
                           2025: "2025ë…„ ì£¼ìš”í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”" if lang == 'ko' else "Please show 2025 key statistics"}
            for year in [2022, 2023, 2024, 2025]:
                if st.button(year_btn_text[year], key=f"stats_{year}"):
                    st.session_state.example_question = year_q_text[year]
        
        with col18:
            st.markdown(t['wacc_trend'])
            if st.button(t['btn_wacc_trend'], key="wacc_trend_analysis"):
                st.session_state.example_question = t['q_wacc_trend']
        
        # ì‚¬ìš©ì ì…ë ¥
        user_question = st.text_input(
            t['input_question'],
            value=st.session_state.get("example_question", ""),
            placeholder=t['input_placeholder']
        )
        
        if st.button(t['btn_ask'], key="ask_question") or user_question:
            if user_question:
                # ì˜ì–´ ì§ˆë¬¸ì„ í•œê¸€ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
                original_question = user_question
                user_question = translate_question_to_korean(user_question)
                
                # ë°ì´í„° ê²€ìƒ‰
                if "ìœ ì‚¬ê¸°ì—…" in user_question or "ìœ ì‚¬" in user_question:
                    # ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
                    smart_search = get_smart_search_system()
                    matches = smart_search.smart_search(user_question)
                    
                    if matches:
                        # ìƒìœ„ ë§¤ì¹­ ê²°ê³¼ë¡œ ê²€ìƒ‰
                        top_match = matches[0]
                        search_keyword = top_match['keyword']
                        
                        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                        st.info(f"ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ê²°ê³¼:")
                        st.info(f"   ìµœì  ë§¤ì¹­: '{search_keyword}' ({top_match['match_type']}, ì‹ ë¢°ë„: {top_match['confidence']:.2f})")
                        
                        if 'related_keywords' in top_match and len(top_match['related_keywords']) > 1:
                            st.info(f"   ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(top_match['related_keywords'][:3])}")
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
                        data = search_similar_companies(search_keyword)
                        
                        if not data.empty:
                            st.success(f"âœ… '{search_keyword}' ê´€ë ¨ ìœ ì‚¬ê¸°ì—… {len(data)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            
                            # êµ¬ì¡°í™”ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ ìƒì„± (API ì—†ì´ë„ ë‹µë³€ ê°€ëŠ¥)
                            st.markdown("### ğŸ“Š ìœ ì‚¬ê¸°ì—… ì„ ì • ì •ë³´")
                            
                            # ìë™ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë¬¸ì¥ ìƒì„±
                            structured_answer = generate_structured_sentences(data)
                            if structured_answer and structured_answer.strip():
                                st.markdown(structured_answer)
                            else:
                                st.warning("êµ¬ì¡°í™”ëœ ë¬¸ì¥ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ì›ë³¸ ë°ì´í„°ë„ í‘œ í˜•íƒœë¡œ í‘œì‹œ (ì°¸ê³ ìš©)
                            st.markdown("### ğŸ“Š ì›ë³¸ ë°ì´í„° (ì°¸ê³ ìš©)")
                            display_data = data.copy()
                            
                            # ì£¼ìš”ì‚¬ì—… ì»¬ëŸ¼ ê¸¸ì´ ì œí•œ
                            if 'í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…' in display_data.columns:
                                display_data['í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…'] = display_data['í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…'].astype(str).apply(
                                    lambda x: x[:50] + "..." if len(x) > 50 else x
                                )
                            
                            # í‘œ í˜•íƒœë¡œ ë°ì´í„° í‘œì‹œ
                            st.dataframe(
                                display_data[['ë°œí–‰ì¼ì', 'ê³µì‹œë³´ê³ ì„œëª…','ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…', 'ìœ ì‚¬ê¸°ì—…', 'Link']],
                                width='stretch',
                                hide_index=True
                            )
                            
                            # ìš”ì•½ ì •ë³´ í‘œì‹œ
                            st.markdown("### ğŸ“ˆ ìš”ì•½ ì •ë³´")
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("ì´ ê±´ìˆ˜", len(data))
                            
                            with col2:
                                unique_companies = data['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'].nunique()
                                st.metric("ê³µì‹œë°œí–‰ ê¸°ì—… ìˆ˜", unique_companies)
                            
                            with col3:
                                unique_targets = data['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'].nunique()
                                st.metric("í‰ê°€ëŒ€ìƒ ê¸°ì—… ìˆ˜", unique_targets)
                            
                            
                        else:
                            st.warning(f"'{search_keyword}'ì™€ ê´€ë ¨ëœ ìœ ì‚¬ê¸°ì—… ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            st.info("ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
                            return
                    else:
                        # ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                        st.info("ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        
                        # ê¸°ì¡´ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§ (í´ë°±)
                        business_keywords = []
                        question_lower = user_question.lower()
                        
                        # ë¯¸ë¦¬ ì •ì˜ëœ í‚¤ì›Œë“œì—ì„œ ì°¾ê¸°
                        common_businesses = ['ìŒì›', 'ê°€ìƒìì‚°', 'ê²Œì„', 'ê¸ˆìœµ', 'ì œì¡°', 'ì„œë¹„ìŠ¤', 'IT', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í•˜ë“œì›¨ì–´', 'ë°”ì´ì˜¤', 'ì œì•½', 'í™”í•™', 'ì² ê°•', 'ìë™ì°¨', 'ê±´ì„¤', 'ë¶€ë™ì‚°', 'ìœ í†µ', 'ì‹í’ˆ', 'ìŒë£Œ', 'ì˜ë¥˜', 'í™”ì¥í’ˆ', 'ì—¬í–‰', 'í•­ê³µ', 'ì„ ë°•', 'ì—ë„ˆì§€', 'ì „ë ¥', 'ê°€ìŠ¤', 'í†µì‹ ', 'ë¯¸ë””ì–´', 'êµìœ¡', 'ì˜ë£Œ', 'ë³´í—˜', 'ì€í–‰', 'ì¦ê¶Œ', 'íˆ¬ì', 'í€ë“œ', 'ë¶€ë™ì‚°ì‹ íƒ', 'ë¦¬ì¸ ', 'ì •ë³´ë³´ì•ˆ', 'ë³´ì•ˆ', 'ì‚¬ì´ë²„ë³´ì•ˆ', 'ë³´ì•ˆì†”ë£¨ì…˜', 'ë³´ì•ˆì‹œìŠ¤í…œ']
                        
                        for business in common_businesses:
                            if business in question_lower:
                                business_keywords.append(business)
                                break
                        
                        if not business_keywords:
                            # ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ
                            import re
                            patterns = [r'(\w+)\s*ì‚¬ì—…', r'(\w+)\s*ì—…ì¢…', r'(\w+)\s*ê¸°ì—…', r'(\w+)\s*íšŒì‚¬', r'(\w+)\s*ì—…ê³„']
                            for pattern in patterns:
                                matches = re.findall(pattern, user_question)
                                if matches:
                                    business_keywords.extend(matches)
                                    break
                        
                        if not business_keywords:
                            business_keywords = [user_question.replace('ìœ ì‚¬ê¸°ì—…', '').replace('ì€', '').replace('ëŠ”', '').replace('ë¬´ì—‡ì¸ê°€ìš”', '').replace('?', '').strip()]
                        
                        search_keyword = business_keywords[0] if business_keywords else "ì¼ë°˜"
                        st.info(f"ğŸ” '{search_keyword}' ê´€ë ¨ ìœ ì‚¬ê¸°ì—…ì„ ê²€ìƒ‰ ì¤‘...")
                        data = search_similar_companies(search_keyword)
                        
                        if data.empty:
                            st.warning(f"'{search_keyword}'ì™€ ê´€ë ¨ëœ ìœ ì‚¬ê¸°ì—… ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            st.info("ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
                            return
                        
                        st.success(f"âœ… '{search_keyword}' ê´€ë ¨ ìœ ì‚¬ê¸°ì—… {len(data)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        
                        # êµ¬ì¡°í™”ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ ìƒì„± (API ì—†ì´ë„ ë‹µë³€ ê°€ëŠ¥)
                        st.markdown("### ğŸ“Š ìœ ì‚¬ê¸°ì—… ì„ ì • ì •ë³´")
                        
                        # ìë™ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë¬¸ì¥ ìƒì„±
                        structured_answer = generate_structured_sentences(data)
                        if structured_answer and structured_answer.strip():
                            st.markdown(structured_answer)
                        else:
                            st.warning("êµ¬ì¡°í™”ëœ ë¬¸ì¥ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ì›ë³¸ ë°ì´í„°ë„ í‘œ í˜•íƒœë¡œ í‘œì‹œ (ì°¸ê³ ìš©)
                        st.markdown("### ğŸ“Š ì›ë³¸ ë°ì´í„° (ì°¸ê³ ìš©)")
                        
                        # ë°ì´í„° ì •ë¦¬ ë° í‘œì‹œ
                        display_data = data.copy()
                        
                        # ì£¼ìš”ì‚¬ì—… ì»¬ëŸ¼ ê¸¸ì´ ì œí•œ
                        if 'í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…' in display_data.columns:
                            display_data['í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…'] = display_data['í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…'].astype(str).apply(
                                lambda x: x[:50] + "..." if len(x) > 50 else x
                            )
                        
                        # í‘œ í˜•íƒœë¡œ ë°ì´í„° í‘œì‹œ
                        st.dataframe(
                            display_data[['ë°œí–‰ì¼ì', 'ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…', 'ìœ ì‚¬ê¸°ì—…', 'ê³µì‹œë³´ê³ ì„œëª…']],
                            width='stretch',
                            hide_index=True
                        )
                        
                        # ìš”ì•½ ì •ë³´ í‘œì‹œ
                        st.markdown("### ğŸ“ˆ ìš”ì•½ ì •ë³´")
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("ì´ ê±´ìˆ˜", len(data))
                        
                        with col2:
                            unique_companies = data['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…'].nunique()
                            st.metric("ê³µì‹œë°œí–‰ ê¸°ì—… ìˆ˜", unique_companies)
                        
                        with col3:
                            unique_targets = data['í‰ê°€ëŒ€ìƒê¸°ì—…ëª…'].nunique()
                            st.metric("í‰ê°€ëŒ€ìƒ ê¸°ì—… ìˆ˜", unique_targets)
                        
                
                elif any(keyword in user_question for keyword in ["ì‚°ì—…ë³„", "ì¤‘ì•™ê°’", "WACC", "í‰ê°€ë²•ì¸", "ìœ„ë°˜", "ë¯¸ê¸°ì¬", "Top", "ìƒìœ„", "ìµœê·¼", "ì˜êµ¬í˜„ê¸ˆíë¦„", "ë¹„ì˜ì—…ìš©ìì‚°êµ¬ì„±", "ë¹„ì˜ì—…ìì‚°", "ì—…ì¢…", "ê±°ë˜", "íˆ¬ì", "ë§µí•‘", "ë§¤í•‘", "ì£¼ìš”í†µê³„", "í†µê³„", "íŠ¸ë Œë“œ"]):
                    # ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ ì§ˆë¬¸ë“¤ ì²˜ë¦¬
                    st.info(f"ğŸ” ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹: '{user_question}'")
                    processed = process_valuation_analysis(user_question)
                    if processed:
                        return  # ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ í•¨ìˆ˜ ì¢…ë£Œ
                    else:
                        st.warning("í•´ë‹¹ ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                        return
                
                elif "EV/Sales" in user_question or "ì¬ë¬´ë¹„ìœ¨" in user_question:
                    # ì¬ë¬´ë¹„ìœ¨ ê²€ìƒ‰ - ì„¹í„° í‚¤ì›Œë“œ ì¶”ì¶œ
                    sector_keywords = ['ê¸ˆìœµ', 'IT', 'ì œì¡°', 'ì„œë¹„ìŠ¤', 'ë°”ì´ì˜¤', 'ê²Œì„', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í™”í•™', 'ì² ê°•', 'ìë™ì°¨', 'ê±´ì„¤', 'ë¶€ë™ì‚°', 'ìœ í†µ', 'ì‹í’ˆ', 'ìŒë£Œ', 'ì˜ë¥˜', 'í™”ì¥í’ˆ', 'ì—¬í–‰', 'í•­ê³µ', 'ì„ ë°•', 'ì—ë„ˆì§€', 'ì „ë ¥', 'ê°€ìŠ¤', 'í†µì‹ ', 'ë¯¸ë””ì–´', 'êµìœ¡', 'ì˜ë£Œ', 'ë³´í—˜', 'ì€í–‰', 'ì¦ê¶Œ', 'íˆ¬ì', 'í€ë“œ', 'ë¶€ë™ì‚°ì‹ íƒ', 'ë¦¬ì¸ ', 'ì •ë³´ë³´ì•ˆ', 'ë³´ì•ˆ', 'ì‚¬ì´ë²„ë³´ì•ˆ', 'ë³´ì•ˆì†”ë£¨ì…˜', 'ë³´ì•ˆì‹œìŠ¤í…œ']
                    
                    sector = None
                    for keyword in sector_keywords:
                        if keyword in user_question:
                            sector = keyword
                            break
                    
                    # ì„¹í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ê°’
                    if sector is None:
                        sector = "ê¸ˆìœµ"
                    
                    # ë‚ ì§œ í•„í„° ì¶”ì¶œ - ë” ìœ ì—°í•œ íŒ¨í„´ ë§¤ì¹­
                    start_date = None
                    import re
                    
                    # ì—°ë„ íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: 2022, 2023, 2024 ë“±)
                    year_patterns = [
                        r'(\d{4})ë…„ ì´í›„',
                        r'(\d{4})ë…„ë¶€í„°',
                        r'(\d{4}) ì´í›„',
                        r'(\d{4})ë¶€í„°',
                        r'(\d{4})ë…„'
                    ]
                    
                    for pattern in year_patterns:
                        match = re.search(pattern, user_question)
                        if match:
                            year = int(match.group(1))
                            start_date = f"{year}-01-01"
                            break
                    
                    data = search_financial_ratios(sector, start_date=start_date)
                    if not data.empty:
                        # ê²€ìƒ‰ ì¡°ê±´ í‘œì‹œ
                        search_info = f"âœ… {sector}ì—… ì¬ë¬´ë¹„ìœ¨ ë°ì´í„° {len(data)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                        if start_date:
                            search_info += f" (ê²€ìƒ‰ ê¸°ê°„: {start_date} ì´í›„)"
                        st.success(search_info)
                        
                        # ê²€ìƒ‰ ì¡°ê±´ ìš”ì•½
                        st.info(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´: ì„¹í„°='{sector}'" + (f", ì‹œì‘ì¼='{start_date}'" if start_date else ""))
                        
                        # ì¬ë¬´ë¹„ìœ¨ ë°ì´í„° í‘œì‹œ
                        st.markdown("### ğŸ“Š ì¬ë¬´ë¹„ìœ¨ ë°ì´í„°")
                        
                        # EV/Sales ê°’ì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
                        if 'EV/Sales' in data.columns:
                            ev_sales_data = data[data['EV/Sales'].notna() & (data['EV/Sales'] != '')]
                            if not ev_sales_data.empty:
                                st.markdown("#### EV/Sales ê°’")
                                display_cols = ['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'EV/Sales']
                                st.dataframe(ev_sales_data[display_cols], width='stretch', hide_index=True)
                                
                                # EV/Sales í†µê³„
                                try:
                                    ev_sales_values = pd.to_numeric(ev_sales_data['EV/Sales'], errors='coerce')
                                    ev_sales_values = ev_sales_values.dropna()
                                    if not ev_sales_values.empty:
                                        st.markdown("#### EV/Sales í†µê³„")
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            st.metric("í‰ê· ", f"{ev_sales_values.mean():.2f}")
                                        with col2:
                                            st.metric("ì¤‘ê°„ê°’", f"{ev_sales_values.median():.2f}")
                                        with col3:
                                            st.metric("ìµœì†Œê°’", f"{ev_sales_values.min():.2f}")
                                        with col4:
                                            st.metric("ìµœëŒ€ê°’", f"{ev_sales_values.max():.2f}")
                                except:
                                    pass
                            else:
                                st.warning("EV/Sales ê°’ì´ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ì „ì²´ ì¬ë¬´ë¹„ìœ¨ ë°ì´í„° í‘œì‹œ
                        st.markdown("#### ì „ì²´ ì¬ë¬´ë¹„ìœ¨ ë°ì´í„°")
                        display_cols = ['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'ë°œí–‰ì¼ì', 'EV/Sales', 'PSR', 'WACC']
                        available_cols = [col for col in display_cols if col in data.columns]
                        st.dataframe(data[available_cols], width='stretch', hide_index=True)
                        
                        
                    else:
                        st.warning(f"{sector}ì—… ì¬ë¬´ë¹„ìœ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return
                else:
                    # ì¼ë°˜ ê¸°ì—… ê²€ìƒ‰
                    data = search_by_sector(user_question)
                    if not data.empty:
                        st.success(f"âœ… '{user_question}' ê´€ë ¨ ë°ì´í„° {len(data)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return
                
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab2:
        st.header(t['search_header'])
        
        # ê²€ìƒ‰ ì˜µì…˜
        search_options = [t['company_name'], t['industry'], t['business'], t['issue_date']]
        search_option_map = {
            t['company_name']: "ê¸°ì—…ëª…",
            t['industry']: "ì‚°ì—…ë¶„ë¥˜", 
            t['business']: "ì£¼ìš”ì‚¬ì—…",
            t['issue_date']: "ë°œí–‰ì¼ì"
        }
        
        search_option_display = st.selectbox(
            t['search_type'],
            search_options
        )
        search_option = search_option_map[search_option_display]
        
        if search_option == "ê¸°ì—…ëª…":
            search_term = st.text_input(t['enter_company'])
        elif search_option == "ì‚°ì—…ë¶„ë¥˜":
            search_term = st.text_input(t['enter_industry'])
        elif search_option == "ì£¼ìš”ì‚¬ì—…":
            search_term = st.text_input(t['enter_business'])
        else:  # ë°œí–‰ì¼ì
            # DBì—ì„œ ìµœì†Œ/ìµœëŒ€ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
            conn = get_db_connection()
            min_date = None
            max_date = None
            if conn:
                try:
                    date_query = "SELECT MIN(ë°œí–‰ì¼ì) as min_date, MAX(ë°œí–‰ì¼ì) as max_date FROM ì™¸í‰ë³´ê³ ì„œ WHERE ë°œí–‰ì¼ì IS NOT NULL"
                    date_df = pd.read_sql_query(date_query, conn)
                    conn.close()
                    if not date_df.empty and pd.notna(date_df.iloc[0]['min_date']):
                        min_date = pd.to_datetime(date_df.iloc[0]['min_date']).date()
                        max_date = pd.to_datetime(date_df.iloc[0]['max_date']).date()
                except:
                    if conn:
                        conn.close()
            
            # ë‚ ì§œ ë²”ìœ„ ì„ íƒ (ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼)
            if min_date and max_date:
                # ê¸°ë³¸ê°’: ìµœê·¼ 1ë…„
                from datetime import timedelta
                default_end = max_date
                default_start = max(default_end - timedelta(days=365), min_date)
                
                date_range = st.date_input(
                    t['select_date'],
                    value=(default_start, default_end),
                    min_value=min_date,
                    max_value=max_date,
                    help=t['select_date']
                )
            else:
                date_range = st.date_input(
                    t['select_date'],
                    value=None,
                    help=t['select_date']
                )
        
        if st.button(t['search_button'], key="search_button"):
            if search_option == "ë°œí–‰ì¼ì":
                # ë‚ ì§œ ë²”ìœ„ ì²˜ë¦¬
                if date_range:
                    try:
                        if isinstance(date_range, tuple):
                            if len(date_range) == 2:
                                # ê¸°ê°„ ë²”ìœ„ ì„ íƒ (ì‹œì‘ì¼, ì¢…ë£Œì¼)
                                start_date = date_range[0]
                                end_date = date_range[1]
                                if start_date and end_date:
                                    start_date_str = start_date.strftime("%Y-%m-%d")
                                    end_date_str = end_date.strftime("%Y-%m-%d")
                                    data = search_by_date_range(start_date_str, end_date_str)
                                else:
                                    st.warning("ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                    data = pd.DataFrame()
                            elif len(date_range) == 1:
                                # ë‹¨ì¼ ë‚ ì§œë§Œ ì„ íƒ (íŠœí”Œì— í•˜ë‚˜ë§Œ)
                                start_date = date_range[0]
                                if start_date:
                                    start_date_str = start_date.strftime("%Y-%m-%d")
                                    data = search_by_date_range(start_date_str, start_date_str)
                                else:
                                    st.warning("ë°œí–‰ì¼ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                    data = pd.DataFrame()
                            else:
                                st.warning("ë°œí–‰ì¼ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                data = pd.DataFrame()
                        else:
                            # ë‹¨ì¼ ë‚ ì§œ ê°ì²´ (date ê°ì²´)
                            start_date_str = date_range.strftime("%Y-%m-%d")
                            data = search_by_date_range(start_date_str, start_date_str)
                    except Exception as e:
                        st.error(f"ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        data = pd.DataFrame()
                else:
                    st.warning("ë°œí–‰ì¼ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    data = pd.DataFrame()
            elif search_term:
                # ê²€ìƒ‰ ì˜µì…˜ì— ë”°ë¼ ë‹¤ë¥¸ ê²€ìƒ‰ í•¨ìˆ˜ ì‚¬ìš©
                if search_option == "ê¸°ì—…ëª…":
                    data = search_by_company_name(str(search_term))
                elif search_option == "ì‚°ì—…ë¶„ë¥˜":
                    data = search_by_sector(str(search_term))
                elif search_option == "ì£¼ìš”ì‚¬ì—…":
                    data = search_by_business(str(search_term))
                
            else:
                if search_option != "ë°œí–‰ì¼ì":
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    data = pd.DataFrame()
            
            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
            if 'data' in locals() and data is not None and not data.empty:
                # ê²€ìƒ‰ ì¡°ê±´ í‘œì‹œ
                if search_option == "ë°œí–‰ì¼ì" and date_range:
                    try:
                        if isinstance(date_range, tuple) and len(date_range) == 2 and date_range[0] and date_range[1]:
                            st.info(f"ğŸ” ê²€ìƒ‰ ê¸°ê°„: {date_range[0].strftime('%Y-%m-%d')} ~ {date_range[1].strftime('%Y-%m-%d')}")
                        else:
                            date_display = date_range[0] if (isinstance(date_range, tuple) and len(date_range) > 0) else date_range
                            if date_display:
                                st.info(f"ğŸ” ê²€ìƒ‰ ë‚ ì§œ: {date_display.strftime('%Y-%m-%d')}")
                    except:
                        pass
                
                    st.success(f"âœ… ê²€ìƒ‰ ê²°ê³¼ {len(data)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    
                    # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
                    display_columns = ['ê³µì‹œë°œí–‰_ê¸°ì—…ëª…', 'ê³µì‹œë°œí–‰_ê¸°ì—…_ì‚°ì—…ë¶„ë¥˜', 'í‰ê°€ëŒ€ìƒê¸°ì—…ëª…', 'í‰ê°€ëŒ€ìƒ_ì£¼ìš”ì‚¬ì—…', 'ë°œí–‰ì¼ì']
                    
                    # ì¶”ê°€ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ë©´ í‘œì‹œ ì»¬ëŸ¼ì— ì¶”ê°€
                    if 'ìœ ì‚¬ê¸°ì—…' in data.columns:
                        display_columns.append('ìœ ì‚¬ê¸°ì—…')
                    if 'WACC' in data.columns:
                        display_columns.append('WACC')
                    if 'Link' in data.columns:
                        display_columns.append('Link')
                if 'ê³µì‹œë³´ê³ ì„œëª…' in data.columns:
                    display_columns.insert(0, 'ê³µì‹œë³´ê³ ì„œëª…')
                
                # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ
                available_columns = [col for col in display_columns if col in data.columns]
                st.dataframe(data[available_columns], width='stretch', hide_index=True)
            elif 'data' in locals():
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
